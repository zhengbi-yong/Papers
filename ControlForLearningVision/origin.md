人工智能随着并行计算的硬件以及计算机技术的发展迎来了又一波高潮，但其缺乏成体系的理论指导。控制理论作为一门已经发展了数十年的学科，形成了一套完备的方法论以及系统的设计思想。将控制理论中的思想应用于人工智能模型的设计本身或者指导人工智能模型的设计过程可能能够进一步推动人工智能社区的发展。
控制所做的事情大致分为两个部分：分析和综合。其中分析是指通过理论来得到一个系统的某种性质，例如稳定性。综合则是在理论的指导下改善系统的性能或者设计新的系统。
这两者在人工智能领域也是非常重要的两个任务，只是目前人工智能缺乏手段去分析一个模型的某个性质，也缺乏理论指导去设计新的模型。但在没有理论指导的情况下，人工智能社区的研究者们也十分聪明的提出了蕴含着控制理论思想的模型结构。
比如ResNet的残差连接，它实际上蕴含着负反馈的朴素思想，从学习一个绝对的值变成去学习这个值和目标之间的偏差，从而巧妙地解决了梯度消失和梯度爆炸的问题。又比如DenseNet提出的密集连接，它实际上体现了控制理论当中的前馈的思想，巧妙地复用了浅层特征提取模块的特征。比如最新出现的Mamba，它巧妙地使用了多个状态空间模型去将非线性时变系统建模成线性时不变的模型。
在上述成果涌现出来之后，我们意识到了控制理论潜在的巨大能力，即以控制理论已经有的丰硕成果应用于蓬勃发展的人工智能之中，从而使得人工智能的研究更加成体系，有条理。


1.优化
Accelerated optimization in deep learning with a proportional-integral-derivative controller
高性能优化算法对于深度学习至关重要。然而，由于算法的不稳定性和可解释性较弱，理解优化行为（即学习过程）仍然具有挑战性。由于基于梯度的优化可以解释为连续时间动态系统，因此将反馈控制应用于对优化器进行建模的动态系统可以为探索更稳健、更准确和可解释的优化算法提供另一种视角。在这项研究中，我们提出了一个称为受控重球优化器的优化框架。通过在优化器中采用比例积分微分 (PID) 控制器，我们开发了一种称为比例积分微分加速优化器 (PIDAO) 的确定性连续时间优化器，并提供了 PIDAO 在无约束（非）凸条件下的理论收敛分析。优化。作为副产品，我们通过使用特定的离散化方法推导出用于训练深度神经网络的 PIDAO 系列方案。与经典优化器相比，由于 PID 控制器的特性，PIDAO 可以被经验证明具有更积极的能力，以更低的计算成本探索损失景观。实验评估表明，PIDAO可以加速收敛并提高深度学习的准确性，与先进算法相比，实现了state-of-the-art的性能。
2.最优控制
PDE MODELS FOR DEEP NEURAL NETWORKS: LEARNING THEORY, CALCULUS OF VARIATIONS AND OPTIMAL CONTROL
我们通过采用网络宽度和深度的连续统限制，提出了深度神经网络（DNN）及其相关学习问题的偏微分积分方程（PDE）框架。所提出的模型捕获了隐藏节点之间的复杂交互，克服了传统离散和常微分方程（ODE）模型的局限性。我们探索了前向传播问题的适定性，分析了学习任务的最小化器的存在性和性质，并详细检查了临界点存在的充分必要条件。使用变分微积分、庞特里亚金极大值原理和 Hamilton-Jacobi-Bellman 方程建立了学习任务及其相关 PDE 前向问题的可控性和最优性条件，将深度学习过程构建为 PDE 约束优化问题。在这种情况下，我们证明了后者粘度解的存在，并基于值泛函建立了最优反馈控制。这种方法有助于开发新的网络架构和数值方法，通过引入前向-后向 PDE 离散化来改进传统的逐层梯度下降技术。该论文为连接神经网络、偏微分方程理论、变分分析和最优控制提供了数学基础，部分建立在并扩展了[28]的结果，其中主要焦点是前向演化的分析。通过整合这些领域，我们提供了一个强大的框架，可以增强深度学习模型的稳定性、效率和可解释性。
3.系统辨识
Physics-Constrained Taylor Neural Networks  for Learning and Control of Dynamical Systems
由于传感器数据的准确性和可用性的提高，数据驱动的方法在识别动力系统方面越来越受欢迎。然而，仅仅依靠数据进行识别并不能保证所识别的系统将保持其物理特性，或者预测的模型将能够很好地概括。在本文中，我们提出了一种新的系统识别方法，通过将神经网络集成为泰勒级数展开的一阶导数，而不是直接学习动态函数。这种方法称为单调泰勒神经网络（MTNN），旨在通过将神经网络模型的输出条件限制为始终非正或非负来确保动力系统的单调特性。这些条件通过两种方式构建：通过设计新的神经网络架构或通过正则化训练的损失函数。当使用来自两个现实系统（包括 HVAC 和 TCLab）的实验数据进行测试时，所提出的方法表现出比不限制系统单调属性的方法更好的性能。此外，当将模型预测控制器用于非线性MIMO系统时，MTNN在实际控制应用中表现出良好的性能，说明了该方法的实际应用。
4.MPC
UNIFYING BACK-PROPAGATION AND FORWARD-FORWARD  ALGORITHMS THROUGH MODEL PREDICTIVE CONTROL
我们引入了模型预测控制（MPC）框架来训练深度神经网络，系统地统一了反向传播（BP）和前向-前向（FF）算法。同时，它产生了一系列具有不同展望范围的中间训练算法，从而导致性能与效率的权衡。我们在深度线性网络上对这种权衡进行了精确分析，其中定性结论适用于一般网络。根据我们的分析，我们提出了一种根据给定目标和模型规范选择优化范围的原则方法。各种模型和任务的数值结果证明了我们方法的多功能性。
5.强化学习
A General Control-Theoretic Approach for Reinforcement Learning: Theory and Algorithms
我们设计了一种控制理论强化学习方法来支持最优策略的直接学习。我们建立了我们方法的各种理论特性，例如控制理论算子的收敛性和最优性、新的控制策略参数梯度上升定理以及基于该定理的特定梯度上升算法。作为一个代表性的例子，我们使我们的方法适应特定的控制理论框架，并根据经验评估其在几个经典强化学习任务上的性能，证明我们的控制理论方法在解决方案质量、样本复杂性和运行时间方面比状态的显着改进。最先进的基线方法。
6.状态空间模型
Hamba: Single-view 3D Hand Reconstruction with Graph-guided Bi-Scanning Mamba
由于关节运动、自遮挡以及与物体的交互，从单个 RGB 图像重建 3D 手部具有挑战性。现有的 SOTA 方法采用基于注意力的 Transformer 来学习 3D 手部姿势和形状，但由于关节空间关系建模不足，无法实现鲁棒且准确的性能。为了解决这个问题，我们提出了一种新颖的图引导 Mamba 框架，名为 Hamba，它连接了图学习和状态空间建模。我们的核心思想是使用一些有效的标记将 Mamba 的扫描重新表述为图形引导的双向扫描以进行 3D 重建。这使我们能够学习关节关系和空间序列，以提高重建性能。具体来说，我们设计了一种新颖的图引导状态空间（GSS）块，它可以学习图结构关系和关节的空间序列，并且比基于注意力的方法使用的标记少 88.5%。此外，我们使用融合模块集成状态空间特征和全局特征。通过利用GSS块和融合模块，Hamba有效地利用了图引导的状态空间建模特征，并共同考虑全局和局部特征来提高性能。对多个基准测试和野外测试的大量实验表明，Hamba 的性能显着优于现有的 SOTA，在 FreiHAND 上实现了 5.3mm 的 PA-MPVPE 和 0.992 的 F@15mm。 Hamba 目前在 3D 手部重建的两个具有挑战性的竞赛排行榜2中排名第一。该代码将在接受后可用。
7.状态空间模型
STATE-SPACE MODELING IN LONG SEQUENCE PROCESSING:  A SURVEY ON RECURRENCE IN THE TRANSFORMER ERA
有效地从序列数据中学习是人工智能的长期目标，特别是在长序列的情况下。从机器学习诞生之日起，一些研究人员就致力于寻找能够处理模式序列的算法和架构，保留有关过去输入的信息，同时仍然利用即将到来的数据，而不丢失宝贵的长期依赖性和相关性。虽然这样的最终目标是受到人类连续实时处理感官信息的标志的启发，但一些解决方案通过人为限制处理的上下文或处理预先给出的有限长度的序列来简化学习范式。无处不在的变形金刚进一步强调了这些解决方案，它们最初掩盖了循环神经网络的作用。然而，由于（深度）状态空间模型和大上下文 Transformer 的新颖实例的日益流行，循环网络最近面临着强劲的复兴，它们都基于循环计算，超越了当前普遍存在的技术的一些限制。事实上，随着时间的推移，大型语言模型的快速发展增强了人们对处理数据的有效解决方案的兴趣。这项调查深入总结了基于循环数据处理模型的最新方法。报告和讨论了关于架构和算法解决方案最新趋势的完整分类，为这个有吸引力的研究领域的研究人员提供了指导。新出现的情况表明，有思考新颖路线的空间，这些路线由偏离标准时间反向传播的学习算法构成，走向更现实的场景，在该场景中，利用本地前向计算，有效地在线处理模式，为进一步研究打开了大门。这个话题。
8.状态空间模型
Transformers are SSMs: Generalized Models and Efficient Algorithms  Through Structured State Space Duality
虽然 Transformer 一直是深度学习在语言建模方面取得成功的主要架构，但 Mamba 等状态空间模型 (SSM) 最近已被证明在中小型规模上可以与 Transformer 相媲美或优于 Transformer。  我们证明这些模型家族实际上是非常密切相关的，并在 SSM 和注意力变体之间建立了丰富的理论联系框架，通过对一类经过充分研究的结构化半可分离矩阵的各种分解进行连接。我们的状态空间对偶 (SSD) 框架使我们能够设计一种新架构 (Mamba-2)，其核心层是 Mamba 选择性 SSM 的改进，速度提高了 2-8 倍，同时在语言建模方面继续与 Transformers 竞争。
9.
Towards a Systems Theory of Algorithms
传统上，数值算法被视为仅限于计算机存在的孤立代码片段。然而，这种观点并不适合控制、学习或优化方面的许多现代计算方法，其中体内算法与其环境相互作用。此类开放算法的示例包括各种基于实时优化的控制策略、强化学习、决策架构、在线优化等等。此外，即使是学习或优化中的封闭算法也越来越多地抽象为具有交互动态模块和管道的框图。在这篇观点论文中，我们阐述了我们对待培养的算法系统理论的愿景，并主张将算法视为与其他算法、物理系统、人类或数据库交互的开放动态系统。值得注意的是，在系统理论的框架下开发的多种工具非常适合解决算法领域的一系列挑战。我们调查了正在开发算法系统理论原理的各种实例，并概述了相关的建模、分析和设计挑战。
10.
State Space Model for New-Generation  Network Alternative to Transformers: A Survey
在后深度学习时代，Transformer架构在预训练的大模型和各种下游任务上展现了强大的性能。然而，这种架构巨大的计算需求让许多研究人员望而却步。为了进一步降低注意力模型的复杂性，人们付出了很多努力来设计更有效的方法。其中，状态空间模型（SSM）作为基于自注意力的 Transformer 模型的可能替代品，近年来受到越来越多的关注。在本文中，我们对这些工作进行了第一次全面的回顾，并提供了实验比较和分析，以更好地展示SSM的特点和优势。具体来说，我们首先对原理进行详细描述，以帮助读者快速掌握SSM的关键思想。之后，我们深入审查现有的 SSM 及其各种应用，包括自然语言处理、计算机视觉、图、多模态和多媒体、点云/事件流、时间序列数据和其他领域。此外，我们对这些模型进行了统计比较和分析，希望能帮助读者了解不同结构在各种任务上的有效性。然后，我们提出该方向可能的研究点，以更好地促进SSM理论模型和应用的发展。更多相关工作将在以下 GitHub https://github.com/Event-AHU/Mamba 状态空间模型论文列表中持续更新。
11.
A Cloud-Edge Framework for EnergyEfficient Event-Driven Control: An  Integration of Online Supervised  Learning, Spiking Neural Networks and  Local Plasticity Rules
This paper presents a novel cloud-edge framework for addressing computational and energy constraints in complex control systems. Our approach centers around a learning-based controller using Spiking Neural Networks (SNN) on physical plants. By integrating a biologically plausible learning method with local plasticity rules, we harness the efficiency, scalability, and low latency of SNNs. This design replicates control signals from a cloud-based controller directly on the plant, reducing the need for constant plant-cloud communication. The plant updates weights only when errors surpass predefined thresholds, ensuring efficiency and robustness in various conditions. Applied to linear workbench systems and satellite rendezvous scenarios, including obstacle avoidance, our architecture dramatically lowers normalized tracking error by 96% with increased network size. The event-driven nature of SNNs minimizes energy consumption, utilizing only about 11.1×104 pJ (0.3% of conventional computing requirements). The results demonstrate the system's adjustment to changing work environments and its efficient use of computational and energy resources, with a moderate increase in energy consumption of 27.2% and 37% for static and dynamic obstacles, respectively, compared to non-obstacle scenarios.
12.PID
PID Control-Based Self-Healing to Improve the Robustness  of Large Language Models
尽管深度神经网络在许多自然语言处理应用中都很有效，但最近的研究结果暴露了这些语言模型在引入微小扰动时的脆弱性。虽然在语义上人类无法区分，但这些扰动会显着降低训练有素的语言模型的性能，引发人们对在安全关键情况下部署它们的可靠性的担忧。在这项工作中，我们构建了一个计算高效的自我修复过程，以纠正在线推理过程中当扰动应用于输入数据时出现的不良模型行为。这被表述为轨迹优化问题，其中使用 PID（比例积分微分）控制机制自动校正神经网络层的内部状态。 P 控制器的目标是即时状态调整，而 I 和 D 控制器分别考虑过去的状态和未来的动态趋势。我们利用训练数据的几何特性来设计有效的线性 PID 控制器。这种方法将计算成本降低到仅使用 P 控制器而不是完整 PID 控制的计算成本。此外，我们引入了一种近似最优控制解决方案的分析方法，增强了该受控系统的实时推理能力。此外，我们在简化的设置下对解析解进行了理论误差分析。所提出的基于 PID 控制的自我修复是一种低成本框架，可提高预训练大型语言模型（无论是标准模型还是经过鲁棒训练）针对各种扰动的鲁棒性。详细实现可以参见：https://github.com/zhuotongchen/PID-Control-Based-Self-Healing -to-Improve-the-Robustness-of-Large-Language-Models。
13.PID
PIDformer: Transformer Meets Control Theory
在这项工作中，我们解决了 Transformer 架构的两个主要缺点：输入损坏和输出表示中的等级崩溃。我们将自注意力作为一种自治状态空间模型推出，它本质上促进了其解决方案的平滑性，从而导致较低等级的输出和减少的表示能力。此外，模型的稳态解对输入扰动敏感。我们将带有参考点的比例积分微分 (PID) 闭环反馈控制系统纳入模型中，以提高鲁棒性和表示能力。这种集成旨在保留高频细节，同时增强模型稳定性，使其更具抗噪能力。由此产生的受控状态空间模型在理论上被证明是稳健的并且擅长解决秩崩溃。受此控制框架的启发，我们推导了一类新型变压器，PID控制变压器（PIDformer），旨在提高鲁棒性并减轻softmax变压器固有的等级崩溃问题。我们根据经验评估该模型在各种实际任务中相对于基线转换器的优势和鲁棒性，包括对象分类、图像分割和语言建模。
14.
Reconciling Deep Learning and Control Theory: Recurrent Neural Networks for Indirect Data-Driven Control
本简介旨在讨论循环神经网络 (RNN) 在间接数据驱动控制方面的潜力。事实上，虽然 RNN 长期以来一直被认为是动力系统的通用逼近器，但由于缺乏坚实的理论基础，它们在系统识别和控制中的采用受到了限制。我们在这里打算总结一种解决这一差距的新方法，该方法由两个贡献组成。首先，基于增量输入状态稳定性 (.δISS) 概念，设计了一个用于学习安全且鲁棒的 RNN 模型的框架。然后，在确定了对象的 a.δISS 黑盒模型后，说明了其在设计具有闭环性能保证的基于模型的控制律（例如非线性 MPC）中的用途。最后，概述了主要的开放问题和未来的研究方向。
15.
Real-Time Progressive Learning: Accumulate  Knowledge from Control with  Neural-Network-Based Selective Memory
记忆作为学习的基础，决定着知识的存储、更新和遗忘，进而决定了学习的效率。以记忆机制为特点，提出了一种基于径向基函数神经网络的学习控制方案——实时渐进学习（RTPL），以学习系统的未知动态，并保证稳定性和闭环性能。 RTPL采用选择性记忆递归最小二乘(SMRLS)算法来更新神经网络的权值，而不是传统神经网络学习控制(NNLC)基于Lyapunov的权值更新律，主要关注稳定性和控制性能。具有以下优点：1）无需过滤即可提高学习速度，2）对神经网络超参数设置的鲁棒性，3）良好的泛化能力，即在不同任务中重用学到的知识，以及4）保证参数扰动下的学习性能。此外，RTPL由于其合理分配的内存而实现了知识的不断积累，而NNLC可能会逐渐忘记所学的知识。相应的理论分析和仿真研究证明了RTPL的有效性。
16.
Asymptotically Fair Participation in Machine Learning  Models: an Optimal Control Perspective
当对训练数据集中代表性不足的人口统计数据进行测试时，最先进的机器学习模型的性能通常会恶化。这个问题主要在数据分布是静态的监督学习环境中进行研究。然而，现实世界的应用程序通常涉及由部署的模型引起的分布变化。例如，少数族裔用户的性能差异可能导致较高的客户流失率，因此活跃用户提供的可用数据由于缺乏少数族裔用户而出现偏差。这种反馈效应进一步加剧了未来步骤中不同人口群体之间的差异。为了解决这个问题，我们提出渐近公平参与作为维持所有人口群体的长期模型性能的条件。在这项工作中，我们的目标是通过最优控制公式来解决实现渐近公平参与的问题。此外，我们基于现有的进化种群动态文献设计了一个替代保留系统，以近似活跃用户数量分布变化的动态，其中将实现渐近公平参与的目标表述为最优控制问题，并考虑控制变量作为模型参数。我们应用庞特里亚金极大值原理的有效实现来估计最优控制解决方案。为了评估所提出方法的有效性，我们设计了一个通用的模拟环境，模拟用户保留和模型性能之间反馈效应的群体动态。当我们将生成的模型部署到仿真环境时，最优控制解决方案考虑了长期规划，并且与现有基线方法相比具有卓越的性能。
17.
Transfer learning-based physics-informed convolutional neural network for simulating flow in porous media with timevarying controls
提出了一种基于物理的卷积神经网络（PICNN）来模拟具有时变井控制的多孔介质中的两相流。虽然现有文献中的大多数 PICNN 都致力于参数到状态的映射，但我们提出的网络使用时变控制参数化解决方案，以建立控制到状态的回归。首先，采用有限体积格式离散流动方程并制定遵循质量守恒定律的损失函数。诺伊曼边界条件被无缝地纳入半离散方程中，因此不需要额外的损失项。该网络架构由两个并行的U-Net结构组成，网络输入是井控，输出是系统状态（例如油压和水饱和度）。为了捕获输入和输出之间的时间相关关系，网络经过精心设计，可以模拟离散状态空间方程。我们针对每个时间步长逐步训练网络，使其能够同时预测每个时间步长的油压和水饱和度。对网络进行一个时间步的训练后，我们利用迁移学习技术来加快后续时间步的训练过程。所提出的模型用于模拟具有不同油藏模型维数的油水多孔流动场景，并将计算效率和精度等方面与相应的数值方法进行比较。结果强调了 PICNN 在有效模拟具有大量网格块的系统方面的潜力，因为它的计算时间不随模型维度而变化。此外，我们使用 10 个幅度变化的不同测试控制和另外 10 个具有更高交替频率的控制状态架构来评估时间误差。我们的观察表明，在处理幅度或频率显着变化的控制时，需要更稳健和可靠的模型。
18.
Direct Learning for Parameter-Varying Feedforward Control: A Neural-Network Approach
前馈控制器的性能主要取决于它捕获系统相关动态的程度。本文的目的是开发一种输入输出线性参数变化（LPV）前馈参数化和相应的数据驱动估计方法，其中通过神经网络学习系数对调度信号的依赖性。神经网络的使用使得参数化能够补偿各种恒定相对度 LPV 系统。基于神经网络的控制器的高效优化是通过具有解析梯度的 Levenberg-Marquardt 方法和将 Sanathanan-Koerner 推广到 LPV 情况的伪线性方法实现的。所开发的前馈学习方法的性能在 LPV 系统的模拟研究中得到了验证，表现出优异的性能。
19.
INTERPOLATION, APPROXIMATION AND CONTROLLABILITY OF DEEP NEURAL NETWORKS
我们通过控制理论研究了理想化为连续动力系统的深度残差神经网络的表达能力。具体来说，我们考虑监督学习产生的两个属性，即通用插值（匹配任意输入和目标训练样本的能力）以及密切相关的通用逼近概念（通过流图近似输入-目标函数关系的能力）。在控制族仿射不变性的假设下，我们给出了通用插值的表征，表明它基本上适用于任何非线性架构。此外，我们在一般控制系统的背景下阐明了通用插值和通用逼近之间的关系，表明这两个属性不能相互推论。同时，我们确定了控制族和目标函数的条件，以确保两个概念的等效性。
20.
When Deep Learning Meets Polyhedral Theory:  A Survey
在过去的十年中，由于深度神经网络在计算机视觉和自然语言处理等任务中的卓越准确性，深度学习成为预测建模的流行方法。与此同时，神经网络的结构回归到基于分段常数和分段线性函数的更简单的表示，例如整流线性单元（ReLU），它成为神经网络中最常用的激活函数类型。这使得某些类型的网络结构（例如典型的全连接前馈神经网络）可以通过多面体理论进行分析，并可以应用线性规划（LP）和混合整数线性规划（MILP）等方法来解决各种问题。的目的。在本文中，我们调查了这个快节奏工作领域中出现的主要主题，这为更详细地理解神经网络以及应用线性优化技术来训练、验证和减小此类网络的大小带来了全新的视角。网络。
21.
On the Utility of Koopman Operator Theory in Learning Dexterous Manipulation Skills
尽管基于学习的方法实现了令人印象深刻的灵巧操作能力，但我们尚未看到资源丰富的实验室之外的广泛采用。这可能是由于实际限制，例如巨大的计算负担、难以理解的学习行为、对初始化的敏感性以及实施所需的大量技术专业知识。  在这项工作中，我们研究了库普曼算子理论在减轻这些限制方面的效用。库普曼算子是简单而强大的控制理论结构，可将复杂的非线性动力学表示为高维线性系统。由于复杂的非线性动力学是灵巧操纵的基础，我们开发了一个基于库普曼算子的模仿学习框架，以同时学习机器人手和物体的所需运动。我们证明，库夫曼操作员在灵巧操作方面出奇地有效，并提供了许多独特的好处。值得注意的是，可以通过分析方式学习策略，从而大大减少计算负担并消除对初始化的敏感性以及艰苦的超参数优化的需要。我们的实验表明，基于库普曼算子的方法在成功率和样本效率方面可以与最先进的模仿学习算法相媲美，同时速度快一个数量级。  政策视频可在 https://sites.google.com/view/kodex-corl 上观看。
22.
DeepMartNet - A Martingale based Deep Neural Network Learning Algorithm for Eigenvalue/BVP Problems and Optimal Stochastic Controls*
在本文中，我们提出了一种神经网络学习算法，用于求解椭圆算子的特征值问题和边值问题（BVP）以及高维拟线性抛物线方程的初始BVP（IBVP）以及最优随机控制。该方法基于特征值/BVP/IBVP问题的随机表示中的鞅性质和最优随机控制的鞅原理。基于 Martingale 属性的损失函数可用于通过对与椭圆算子相关的随机过程或随机控制的值过程进行采样来进行有效优化。该算法可用于解决有界或无界域中的特征值问题以及具有 Dirichlet、Neumann 和 Robin 边界的 BVP 和 IBVP 以及一些反馈随机控制问题
23.
Tensor Decompositions Meet Control Theory:  Learning General Mixtures of Linear Dynamical Systems
最近，Chen 和 Poor 发起了线性动力系统混合学习的研究。虽然线性动力系统在时间序列数据建模方面已经有了广泛的应用，但使用混合模型可以更好地拟合甚至更丰富地理解数据中表示的底层子群体。在这项工作中，我们给出了一种基于张量分解的学习线性动力系统混合的新方法。因此，我们的算法在组件上没有强分离条件的情况下就成功了，并且可以用来与轨迹的贝叶斯最优聚类竞争。此外，我们的算法适用于具有挑战性的部分观察环境。我们的出发点是简单但有力的观察，即经典的 Ho-Kalman 算法是用于学习潜变量模型的现代张量分解方法的近亲。这为我们提供了一本如何扩展它以处理更复杂的生成模型的手册。
24.
Forward and Inverse Approximation Theory for  Linear Temporal Convolutional Networks
我们对卷积架构应用于时间序列建模时的近似特性进行了理论分析。具体来说，我们证明了近似率估计（Jackson 型结果）和逆近似定理（Bernstein 型结果），它们共同提供了可以通过时间卷积架构有效捕获的顺序关系类型的全面表征。通过引入精确的复杂性度量，速率估计改进了先前的结果，而逆近似定理是新的。
25.
Deep Neural Network Approximation of Invariant  Functions through Dynamical Systems
我们使用动力系统的流图研究对于输入索引的某些排列不变的函数的近似。此类不变函数包括经过深入研究的涉及图像任务的平移不变函数，但也包含许多在科学和工程中发现新兴应用的排列不变函数。我们通过受控等变动力系统证明了这些函数的通用逼近的充分条件，该系统可以被视为具有对称约束的深度残差网络的一般抽象。这些结果不仅意味着对称函数逼近的各种常用神经网络架构的通用逼近，而且还指导涉及新对称性要求的应用的具有逼近保证的架构设计。
26.
Towards lifelong learning of Recurrent Neural Networks for control design
本文提出了一种循环神经网络（例如 NNARX、ESN、LSTM 和 GRU）的终身学习方法，用作控制系统综合中的对象模型。这个问题很重要，因为在许多实际应用中，需要在新信息可用和/或系统发生变化时调整模型，而不需要随着时间的推移存储越来越多的数据。事实上，在这种背景下，出现了许多问题，例如众所周知的灾难性遗忘和容量饱和问题。我们提出了一种受移动地平线估计器启发的自适应算法，推导了其收敛的条件。所描述的方法应用于模拟化工厂，该方法已在现有文献中被采用作为具有挑战性的基准。讨论了取得的主要成果。
27.
Self-Healing Robust Neural Networks via Closed-Loop  Control
尽管神经网络应用广泛，但人们越来越担心其脆弱性问题。虽然已经开发了许多攻击和防御技术，但这项工作从一个新的角度研究了鲁棒性问题：我们是否可以设计一个能够自动检测和修复漏洞问题的自我修复神经网络？典型的自愈机制是人体的免疫系统。这种受生物学启发的想法已被用于许多工程设计中，但很少在深度学习中进行研究。本文考虑了神经网络的训练后自我修复，并提出了一种闭环控制公式来自动检测和修复由各种攻击或扰动引起的错误。我们提供基于边际的分析来解释该公式如何提高分类器的稳健性。为了加快所提出的自愈网络的推理速度，我们通过改进基于庞特里亚金最大原理的求解器来解决控制问题。最后，我们提出了所提出的具有非线性激活函数的神经网络框架的误差估计。我们针对各种扰动验证了多种网络架构的性能。由于自我修复方法不需要有关数据扰动/攻击的先验信息，因此它可以处理广泛的不可预见的扰动。
28.
On Recurrent Neural Networks for learning-based control:  recent results and ideas for future developments
本文旨在讨论和分析循环神经网络（RNN）在控制设计应用中的潜力。考虑了 RNN 的主要系列，即神经非线性自回归 eXogenous、回声状态网络、长短期记忆和门控循环单元。目标是双重的。首先，调查有关享有输入状态稳定性（ISS）和增量输入状态稳定性（δISS）保证的 RNN 训练的最新结果。其次，讨论仍然阻碍 RNN 广泛用于控制的问题，即它们的鲁棒性、可验证性和可解释性。前一个属性与网络的所谓泛化能力有关，即它们与底层真实植物的一致性，即使存在不可见或扰动的输入轨迹。相反，后者与在 RNN 模型和工厂之间提供清晰的形式连接的可能性有关。在这种情况下，我们将说明 ISS 和 δISS 如何代表 RNN 模型的鲁棒性和可验证性迈出的重要一步，而可解释性的要求为基于物理的网络的使用铺平了道路。还简要讨论了以 RNN 作为被控对象模型的模型预测控制器的设计。最后，本文的一些主要主题在模拟化学系统上进行了说明。
29.
Deep learning via dynamical systems: An approximation perspective
我们建立在深度学习的动态系统方法的基础上，从近似的角度来看，深度残差网络被理想化为连续时间动态系统。特别是，我们使用连续时间深度残差网络建立通用逼近的一般充分条件，这也可以理解为使用动力系统流图的 Lp 逼近理论。在特定情况下，还建立了时间范围内的近似率。总的来说，这些结果表明，通过流图的复合函数逼近提出了逼近理论的新范式，并有助于建立一个有用的数学框架来研究深度学习。
30.
Machine learning and control theory
我们在本章中探讨了机器学习和控制理论之间的联系。控制理论为机器学习提供了有用的概念和工具。相反，机器学习可用于解决大型控制问题。 《数值分析手册》第一部分，我们开发了强化学习和马尔可夫决策过程之间的联系，这是离散时间控制问题。在第二部分中，我们回顾了监督学习的概念以及与静态优化的关系。深度学习扩展了监督学习，可以被视为一个控制问题。在第三部分中，我们介绍随机梯度下降和平均场理论之间的联系。相反，在第四部分和第五部分中，我们回顾随机控制问题的机器学习方法，并重点关注确定性情况，以更轻松地解释数值算法。
31.
TOWARDS ROBUST NEURAL NETWORKS VIA CLOSELOOP CONTROL
尽管深度神经网络在大规模工程应用中取得了成功，但由于其黑盒性质，它很容易受到各种扰动。最近的研究表明，即使输入数据受到难以察觉的干扰，深度神经网络也可能对数据进行错误分类。在本文中，我们从动态系统的角度通过一种新颖的闭环控制方法解决神经网络的鲁棒性问题。不是修改固定神经网络架构中的参数，而是添加闭环控制过程来自适应地针对扰动或损坏的数据生成控制信号。我们使用基础数据的几何信息将神经网络的鲁棒性与最优控制联系起来来设计控制目标。详细分析表明状态轨迹的嵌入流形如何影响所提出方法的误差估计。我们的方法可以同时保持干净数据的性能，并提高针对多种类型数据扰动的鲁棒性。它还可以进一步提高经过稳健训练的神经网络针对不同扰动的性能。据我们所知，这是第一个通过闭环控制提高神经网络鲁棒性的工作
32.
Optimization in Machine Learning: A Distribution Space Approach
我们提出的观点是，机器学习中遇到的优化问题通常可以解释为最小化函数空间上的凸函数，但具有模型参数化引入的非凸约束集。这一观察结果使我们能够通过适当的松弛将此类问题视为训练参数分布空间中的凸优化问题。我们推导出分布空间问题和原始问题之间的一些简单关系，例如分布空间解至少与原始空间中的解一样好。此外，我们开发了一种基于混合分布的数值算法，可以直接在分布空间中执行近似优化。建立了这种近似的一致性，并通过简单的例子说明了所提出算法的数值功效。在理论和实践中，该公式为机器学习中的大规模优化提供了另一种方法。
33.
Deep Learning Theory Review: An Optimal Control  and Dynamical Systems Perspective
近年来，不同学科为提供对深度学习的基本理解而做出的尝试迅速推进，但统一的框架仍然相对有限。在本文中，我们提供了一种通过动力系统和最优控制的视角来调整深度学习理论现有分支的可能方法。通过将深度神经网络视为离散时间非线性动力系统，我们可以使用平均场理论来分析信息如何在各层中传播。当优化算法进一步改写为控制器时，训练过程的最终目标可以表述为最优控制问题。此外，我们可以通过研究优化算法的随机动力学来揭示收敛性和泛化特性。这一观点涵盖了从信息瓶颈到统计物理学的广泛理论研究。当引入最优控制理论时，它还为超参数调整提供了原则性的方法。我们的框架非常适合监督学习，并且可以轻松扩展到其他学习问题，例如贝叶斯学习、对抗性训练和特定形式的元学习。该综述旨在阐明发展深度学习理论时动力学和最优控制的重要性。
34.
Stochastic Modified Equations and Dynamics of Stochastic  Gradient Algorithms I: Mathematical Foundations
我们开发了随机修正方程（SME）框架的数学基础，用于分析随机梯度算法的动力学，其中后者由一类具有小噪声参数的随机微分方程来近似。我们证明这种近似可以在数学上理解为弱近似，这导致了在随机目标的一般设置下随机梯度下降（SGD）、动量 SGD 和随机 Nesterov 加速梯度方法的近似的许多精确且有用的结果。我们还通过显式计算证明，这种连续时间方法可以揭示对所考虑的随机梯度算法的重要分析见解，而这些见解在纯离散时间设置中可能不容易获得。
35.
A Mean-Field Optimal Control Formulation of Deep Learning
最近将深度神经网络和动力系统联系起来的工作开辟了分析深度学习的新途径。特别是，据观察，通过将深度学习重新定义为差分或微分方程的最优控制问题，可以获得新的见解。然而，这种公式的数学方面尚未得到系统的探索。本文介绍了深度学习中群体风险最小化问题的数学公式作为平均场最优控制问题。反映经典最优控制的发展，我们陈述并证明了 Hamilton-Jacobi-Bellman 类型和 Pontryagin 类型的最优条件。这些平均场结果反映了学习问题的概率性质。此外，通过诉诸平均场庞特里亚金极大值原理，我们在总体和经验学习问题之间建立了一些定量关系。这为研究最优控制和深度学习之间的算法和理论联系奠定了数学基础。
36.
An Optimal Control Approach to Deep Learning and  Applications to Discrete-Weight Neural Networks
深度学习被表述为离散时间最优控制问题。这使得人们能够表征最优性的必要条件，并开发不依赖于可训练参数的梯度的训练算法。特别是，我们引入了基于庞特里亚金极大值原理的逐次逼近离散时间方法（MSA）来训练神经网络。获得了离散 MSA 的严格误差估计，这揭示了其动力学和稳定算法的方法。所开发的方法用于以相当有原则的方式训练神经网络，其权重被限制为离散集合中的值。我们获得了有竞争力的性能，有趣的是，在三元网络的情况下，权重非常稀疏，这对于低内存设备中的模型部署可能很有用。
37.
Maximum Principle Based Algorithms for Deep Learning
探索深度学习的连续动态系统方法，以便设计训练算法的替代框架。训练被重新定义为一个控制问题，这使我们能够使用庞特里亚金极大值原理（PMP）在连续时间内制定必要的最优条件。然后使用逐次逼近方法的修改来求解 PMP，从而产生了深度学习的替代训练算法。这种方法的优点是可以建立严格的误差估计和收敛结果。我们还表明，它可以避免基于梯度的方法的一些陷阱，例如鞍点附近平坦景观上的缓慢收敛。此外，我们证明，只要可以有效地执行哈密顿最大化，它就能获得良好的初始收敛率迭代——这一步骤仍需要改进。总体而言，该方法为解决与深度学习相关的问题开辟了新途径，例如陷入慢流形以及基于梯度的方法不适用于离散可训练变量。
38.
Stochastic modified equations and adaptive stochastic gradient  algorithms
我们开发了随机修正方程（SME）方法，其中随机梯度算法通过连续时间随机微分方程在弱意义上近似。我们利用连续公式与最优控制理论来推导新颖的自适应超参数调整策略。我们的算法具有具有竞争力的性能，并具有对不同模型和数据集具有鲁棒性的额外优势。这为随机梯度算法的分析和设计提供了通用方法。
39.
Deep Residual Learning for Image Recognition
更深层次的神经网络更难训练。我们提出了一个残差学习框架，以简化比以前使用的网络更深的网络训练。我们明确地将层重新表示为参考层输入的学习残差函数，而不是学习未引用的函数。我们提供了全面的经验证据，表明这些残差网络更容易优化，并且可以通过显着增加的深度来获得准确性。在 ImageNet 数据集上，我们评估深度高达 152 层的残差网络，比 VGG 网络 [41] 深 8 倍，但复杂度仍然较低。这些残差网络的集合在 ImageNet 测试集上实现了 3.57% 的误​​差。该结果在 ILSVRC 2015 分类任务中获得第一名。我们还对 100 层和 1000 层的 CIFAR-10 进行了分析。表示的深度对于许多视觉识别任务至关重要。仅仅由于我们极深的表示，我们在 COCO 目标检测数据集上获得了 28% 的相对改进。深度残差网络是我们提交 ILSVRC 和 COCO 2015 竞赛的基础，我们还在 ImageNet 检测、ImageNet 定位、COCO 检测和 COCO 分割任务中获得了第一名。
40.
MAMKO: MAMBA-BASED KOOPMAN OPERATOR FOR  MODELING AND PREDICTIVE CONTROL
库普曼理论能够将非线性系统转换为线性表示，是建模和控制非线性系统的强大而有效的工具。然而，库普曼算子对复杂系统（特别是时变系统）进行建模的能力受到固定线性状态空间表示的限制。为了解决这一限制，大型语言模型 Mamba 被认为是增强建模能力同时保留线性状态空间结构的有前途的策略。在本文中，我们提出了一个新的框架，即基于 Mamba 的 Koopman 算子（MamKO），与具有恒定 Koopman 算子的 Koopman 模型相比，它提供了增强的模型可预测性和适应性。受 Mamba 结构的启发，MamKO 根据在线数据生成 Koopman 算子；这使得模型能够有效地捕捉非线性系统随时间的动态行为。然后基于所提出的 MamKO 模型开发了模型预测控制系统。通过对基准时不变和时变系统的实验来评估所提出方法的建模和控制性能。实验结果证明了该方法的优越性。此外，我们还进行了消融实验来测试 MamKO 各个成分的有效性。这种方法开启了大型语言模型与控制框架集成的新可能性，并且在高级建模能力和实时控制实施效率之间实现了良好的平衡。
41.
Parameter-Efficient Fine-Tuning with Controls
与低阶适应（LoRA）作为模拟模型适应权重变化的一种手段的普遍解释相反，本文通过将其框架为控制过程来引入另一种观点。具体来说，我们将 LoRA 中的轻量级矩阵概念化为控制模块，其任务是扰乱下游任务中原始、复杂但冻结的块。基于这种新的理解，我们对这些模块的可控性进行了彻底的分析，确定并建立了充分的条件，以促进它们有效集成到下游控制中。此外，通过无参数注意机制纳入非线性，重新设计了控制模块。此修改允许在控制器内混合令牌，从而增强系统的适应性和性能。实证结果证实，在不引入任何额外参数的情况下，这种方法在所有评估的数据集和排名配置上都优于 LoRA 算法。
42.
An Optimal Control View of LoRA and Binary  Controller Design for Vision Transformers
虽然模型微调的最新进展主要强调低秩适应（LoRA）的利用，但我们提出了一种以降低适应矩阵精度为中心的替代方法。特别是，我们背离了将适应矩阵仅视为权重差异的常见观点，并将其重新解释为“控制变量”以干扰预先训练的 ViT 系统。这一新视角能够建立面向控制的框架，促进以庞特里亚金极大值原理为指导的最优控制探索。此外，我们证明，对于有界控制集（例如超立方体），最优控制通常采用边界值，自然导致二元控制器设计。理论分析表明，在深度残差结构的连续理想化中，采用二元控制策略可以达到与全精度对应策略相同的可达状态，这一发现得到了后来的实证研究的证实。我们的研究进一步表明，控制器的等级比其精度更重要。因此，事实证明，选择低精度但高阶的控制可以在实际视觉任务中获得更好的性能。
43.
Mamba: Linear-Time Sequence Modeling with Selective State Spaces
基础模型现在为深度学习中大多数令人兴奋的应用程序提供支持，几乎普遍基于 Transformer 架构及其核心注意力模块。许多次二次时间架构（例如线性注意力、门控卷积和循环模型以及结构化状态空间模型（SSM））已被开发来解决 Transformers 在长序列上的计算效率低下问题，但它们在重要模态上的表现并不好，例如作为语言。我们发现此类模型的一个关键弱点是它们无法执行基于内容的推理，并做出一些改进。首先，简单地让 SSM 参数作为输入的函数，可以解决其离散模态的弱点，允许模型根据当前标记选择性地沿序列长度维度传播或忘记信息。其次，尽管这种变化阻止了高效卷积的使用，但我们在循环模式下设计了一种硬件感知的并行算法。我们将这些选择性 SSM 集成到简化的端到端神经网络架构中，无需注意力机制，甚至不需要 MLP 模块 (Mamba)。 Mamba 享有快速推理（吞吐量比 Transformer 高 5 倍）和序列长度线性缩放，并且其性能在高达百万长度序列的实际数据上得到提高。作为通用序列模型骨干，Mamba 在语言、音频和基因组学等多种模式上实现了最先进的性能。在语言建模方面，我们的 Mamba-3B 模型在预训练和下游评估方面都优于相同大小的 Transformer，并且与两倍大小的 Transformer 相匹配。
44.
PID-Inspired Inductive Biases for Deep Reinforcement Learning in Partially Observable Control Tasks
深度强化学习（RL）已经显示出仅通过数据学习控制系统的巨大潜力。然而，深度强化学习面临的挑战之一是系统的完整状态通常是不可观测的。在这种情况下，政策需要利用观察历史来推断当前状态。同时，训练和测试环境之间的差异使得策略不过度适应训练时看到的观察序列至关重要。因此，在历史编码器足够灵活以提取相关信息和对环境变化保持鲁棒性之间存在重要的平衡行为。为了达到这种平衡，我们向 PID 控制器寻求灵感。我们断言 PID 控制器的成功表明，对于许多控制任务来说，只需要求和和求差即可随时间积累信息。遵循这一原则，我们提出了两种用于编码历史的架构：一种直接使用 PID 特征，另一种扩展了这些核心思想并可用于任意控制任务。与之前的方法相比，我们的编码器生成的策略通常更稳健，并且在各种跟踪任务上实现了更好的性能。除了跟踪任务之外，我们的策略在一系列运动控制任务上的性能平均比之前最先进的方法提高了 1.7 倍。