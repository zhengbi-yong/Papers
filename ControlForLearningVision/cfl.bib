@misc{abellaAsymptoticBehaviorAttention2024,
  title = {The Asymptotic Behavior of Attention in Transformers},
  author = {Abella, {\'A}lvaro Rodr{\'i}guez and Silvestre, Jo{\~a}o Pedro and Tabuada, Paulo},
  year = {2024},
  month = dec,
  number = {arXiv:2412.02682},
  eprint = {2412.02682},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.02682},
  urldate = {2024-12-10},
  abstract = {A key component of transformers is the attention mechanism orchestrating how each token influences the propagation of every other token through a transformer. In this paper we provide a rigorous, mathematical analysis of the asymptotic properties of attention in transformers. Although we present several results based on different assumptions, all of them point to the same conclusion, all tokens asymptotically converge to each other, a phenomenon that has been empirically reported in the literature. Our findings are carefully compared with existing theoretical results and illustrated by simulations and experimental studies using the GPT-2 model.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {/unread,Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control,Mathematics - Dynamical Systems,Mathematics - Optimization and Control},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\DXPH4DKZ\\Abella 等 - 2024 - The Asymptotic Behavior of Attention in Transformers.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\8UZLLWNZ\\2412.html}
}

@misc{ahmadvandCloudedgeFrameworkEnergyefficient2024,
  title = {A Cloud-Edge Framework for Energy-Efficient Event-Driven Control: An Integration of Online Supervised Learning, Spiking Neural Networks and Local Plasticity Rules},
  shorttitle = {A Cloud-Edge Framework for Energy-Efficient Event-Driven Control},
  author = {Ahmadvand, Reza and Sharif, Sarah Safura and Banad, Yaser Mike},
  year = {2024},
  month = apr,
  number = {arXiv:2405.02316},
  eprint = {2405.02316},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.02316},
  urldate = {2024-11-22},
  abstract = {This paper presents a novel cloud-edge framework for addressing computational and energy constraints in complex control systems. Our approach centers around a learning-based controller using Spiking Neural Networks (SNN) on physical plants. By integrating a biologically plausible learning method with local plasticity rules, we harness the efficiency, scalability, and low latency of SNNs. This design replicates control signals from a cloud-based controller directly on the plant, reducing the need for constant plant-cloud communication. The plant updates weights only when errors surpass predefined thresholds, ensuring efficiency and robustness in various conditions. Applied to linear workbench systems and satellite rendezvous scenarios, including obstacle avoidance, our architecture dramatically lowers normalized tracking error by 96\% with increased network size. The event-driven nature of SNNs minimizes energy consumption, utilizing only about 111 nJ (0.3\% of conventional computing requirements). The results demonstrate the system's adjustment to changing work environments and its efficient use of computational and energy resources, with a moderate increase in energy consumption of 27.2\% and 37\% for static and dynamic obstacles, respectively, compared to non-obstacle scenarios.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control},
  annotation = {TLDR: A novel cloud-edge framework for addressing energy constraints in complex control systems by integrating a biologically plausible learning method with local plasticity rules and low latency of SNNs that replicates control signals from a cloud-based controller directly on the plant, reducing the need for constant plant-cloud communication.},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\7XIDBVBG\\Ahmadvand 等 - 2024 - A Cloud-Edge Framework for Energy-Efficient Event-Driven Control An Integration of Online Supervise.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\4IQPEP26\\2405.html}
}

@misc{bakshiTensorDecompositionsMeet2023,
  title = {Tensor Decompositions Meet Control Theory: Learning General Mixtures of Linear Dynamical Systems},
  shorttitle = {Tensor Decompositions Meet Control Theory},
  author = {Bakshi, Ainesh and Liu, Allen and Moitra, Ankur and Yau, Morris},
  year = {2023},
  month = jul,
  number = {arXiv:2307.06538},
  eprint = {2307.06538},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.06538},
  urldate = {2024-11-20},
  abstract = {Recently Chen and Poor initiated the study of learning mixtures of linear dynamical systems. While linear dynamical systems already have wide-ranging applications in modeling time-series data, using mixture models can lead to a better fit or even a richer understanding of underlying subpopulations represented in the data. In this work we give a new approach to learning mixtures of linear dynamical systems that is based on tensor decompositions. As a result, our algorithm succeeds without strong separation conditions on the components, and can be used to compete with the Bayes optimal clustering of the trajectories. Moreover our algorithm works in the challenging partially-observed setting. Our starting point is the simple but powerful observation that the classic Ho-Kalman algorithm is a close relative of modern tensor decomposition methods for learning latent variable models. This gives us a playbook for how to extend it to work with more complicated generative models.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  annotation = {TLDR: A new approach to learning mixtures of linear dynamical systems that is based on tensor decompositions that succeeds without strong separation conditions on the components, and can be used to compete with the Bayes optimal clustering of the trajectories.},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\GZFRYYKA\\Bakshi 等 - 2023 - Tensor Decompositions Meet Control Theory Learning General Mixtures of Linear Dynamical Systems.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\LMVEQHJD\\2307.html}
}

@incollection{bensoussanMachineLearningControl2022,
  title = {Machine Learning and Control Theory},
  booktitle = {Handbook of {{Numerical Analysis}}},
  author = {Bensoussan, Alain and Li, Yiqun and Nguyen, Dinh Phan Cao and Tran, Minh-Binh and Yam, Sheung Chi Phillip and Zhou, Xiang},
  year = {2022},
  volume = {23},
  pages = {531--558},
  publisher = {Elsevier},
  doi = {10.1016/bs.hna.2021.12.016},
  urldate = {2024-11-18},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  isbn = {978-0-323-85059-9},
  langid = {english},
  file = {C:\Users\Sisyphus\Zotero\storage\NDRDJBE9\Bensoussan 等 - 2022 - Machine learning and control theory.pdf}
}

@misc{bonassiLifelongLearningRecurrent2022,
  title = {Towards Lifelong Learning of Recurrent Neural Networks for Control Design},
  author = {Bonassi, Fabio and Xie, Jing and Farina, Marcello and Scattolini, Riccardo},
  year = {2022},
  month = aug,
  number = {arXiv:2208.03980},
  eprint = {2208.03980},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2208.03980},
  urldate = {2024-11-22},
  abstract = {This paper proposes a method for lifelong learning of Recurrent Neural Networks, such as NNARX, ESN, LSTM, and GRU, to be used as plant models in control system synthesis. The problem is significant because in many practical applications it is required to adapt the model when new information is available and/or the system undergoes changes, without the need to store an increasing amount of data as time proceeds. Indeed, in this context, many problems arise, such as the well known Catastrophic Forgetting and Capacity Saturation ones. We propose an adaptation algorithm inspired by Moving Horizon Estimators, deriving conditions for its convergence. The described method is applied to a simulated chemical plant, already adopted as a challenging benchmark in the existing literature. The main results achieved are discussed.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\X72XFDES\\Bonassi 等 - 2022 - Towards lifelong learning of Recurrent Neural Networks for control design.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\9UQQNBZG\\2208.html}
}

@incollection{bonassiReconcilingDeepLearning2024,
  title = {Reconciling Deep Learning and Control Theory: Recurrent Neural Networks for Indirect Data-Driven Control},
  shorttitle = {Reconciling Deep Learning and Control Theory},
  booktitle = {Special {{Topics}} in {{Information Technology}}},
  author = {Bonassi, Fabio},
  editor = {Amigoni, Francesco},
  year = {2024},
  pages = {77--87},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-51500-2_7},
  urldate = {2024-11-22},
  abstract = {This Brief aims to discuss the potential of Recurrent Neural Networks (RNNs) for indirect data-driven control. Indeed, while RNNs have long been known to be universal approximators of dynamical systems, their adoption for system identification and control has been limited by the lack of solid theoretical foundations. We here intend to summarize a novel approach to address this gap, which is structured in two contributions. First, a framework for learning safe and robust RNN models is devised, relying on the Incremental Input-to-State Stability (.{$\delta$}ISS) notion. Then, after a.{$\delta$}ISS black-box model of the plant is identified, its use for the design of model-based control laws (such as Nonlinear MPC) with closed-loop performance guarantees is illustrated. Finally, the main open problems and future research directions are outlined.},
  isbn = {978-3-031-51499-9 978-3-031-51500-2},
  langid = {english},
  file = {C:\Users\Sisyphus\Zotero\storage\DNA49JMN\Bonassi - 2024 - Reconciling Deep Learning and Control Theory Recurrent Neural Networks for Indirect Data-Driven Con.pdf}
}

@misc{bonassiRecurrentNeuralNetworks2022,
  title = {On Recurrent Neural Networks for Learning-Based Control: Recent Results and Ideas for Future Developments},
  shorttitle = {On Recurrent Neural Networks for Learning-Based Control},
  author = {Bonassi, Fabio and Farina, Marcello and Xie, Jing and Scattolini, Riccardo},
  year = {2022},
  month = may,
  number = {arXiv:2111.13557},
  eprint = {2111.13557},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2111.13557},
  urldate = {2024-11-22},
  abstract = {This paper aims to discuss and analyze the potentialities of Recurrent Neural Networks (RNN) in control design applications. The main families of RNN are considered, namely Neural Nonlinear AutoRegressive eXogenous, (NNARX), Echo State Networks (ESN), Long Short Term Memory (LSTM), and Gated Recurrent Units (GRU). The goal is twofold. Firstly, to survey recent results concerning the training of RNN that enjoy Input-to-State Stability (ISS) and Incremental Input-to-State Stability (\${\textbackslash}delta\$ISS) guarantees. Secondly, to discuss the issues that still hinder the widespread use of RNN for control, namely their robustness, verifiability, and interpretability. The former properties are related to the so-called generalization capabilities of the networks, i.e. their consistency with the underlying real plants, even in presence of unseen or perturbed input trajectories. The latter is instead related to the possibility of providing a clear formal connection between the RNN model and the plant. In this context, we illustrate how ISS and \${\textbackslash}delta\$ISS represent a significant step towards the robustness and verifiability of the RNN models, while the requirement of interpretability paves the way to the use of physics-based networks. The design of model predictive controllers with RNN as plant's model is also briefly discussed. Lastly, some of the main topics of the paper are illustrated on a simulated chemical system.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control,Mathematics - Optimization and Control},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\DK68IWNE\\Bonassi 等 - 2022 - On Recurrent Neural Networks for learning-based control recent results and ideas for future develop.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\HRQXRFRB\\2111.html}
}

@misc{caiDeepMartNetMartingaleBased2023,
  title = {{{DeepMartNet}} -- a Martingale Based Deep Neural Network Learning Algorithm for Eigenvalue/{{BVP}} Problems and Optimal Stochastic Controls},
  author = {Cai, Wei},
  year = {2023},
  month = aug,
  number = {arXiv:2307.11942},
  eprint = {2307.11942},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.11942},
  urldate = {2024-11-22},
  abstract = {In this paper, we propose a neural network learning algorithm for solving eigenvalue problems and boundary value problems (BVPs) for elliptic operators and initial BVPs (IBVPs) of quasi-linear parabolic equations in high dimensions as well as optimal stochastic controls. The method is based on the Martingale property in the stochastic representation for the eigenvalue/BVP/IBVP problems and martingale principle for optimal stochastic controls. A loss function based on the Martingale property can be used for efficient optimization by sampling the stochastic processes associated with the elliptic operators or value process for stochastic controls. The proposed algorithm can be used for eigenvalue problems and BVPs and IBVPs with Dirichlet, Neumann, and Robin boundaries in bounded or unbounded domains and some feedback stochastic control problems.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Numerical Analysis,Mathematics - Numerical Analysis},
  annotation = {TLDR: A neural network learning algorithm for eigenvalue and eigenfunction for elliptic operators in high dimensions using the Martingale property in the stochastic representation for the eigen value problem is proposed.},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\QUGKTDVS\\Cai - 2023 - DeepMartNet -- A Martingale based Deep Neural Network Learning Algorithm for EigenvalueBVP Problems.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\EIIL7HUP\\2307.html}
}

@misc{caiOptimizationMachineLearning2020,
  title = {Optimization in Machine Learning: A Distribution Space Approach},
  shorttitle = {Optimization in Machine Learning},
  author = {Cai, Yongqiang and Li, Qianxiao and Shen, Zuowei},
  year = {2020},
  month = apr,
  number = {arXiv:2004.08620},
  eprint = {2004.08620},
  publisher = {arXiv},
  urldate = {2024-11-22},
  abstract = {We present the viewpoint that optimization problems encountered in machine learning can often be interpreted as minimizing a convex functional over a function space, but with a non-convex constraint set introduced by model parameterization. This observation allows us to repose such problems via a suitable relaxation as convex optimization problems in the space of distributions over the training parameters. We derive some simple relationships between the distribution-space problem and the original problem, e.g. a distribution-space solution is at least as good as a solution in the original space. Moreover, we develop a numerical algorithm based on mixture distributions to perform approximate optimization directly in distribution space. Consistency of this approximation is established and the numerical efficacy of the proposed algorithm is illustrated on simple examples. In both theory and practice, this formulation provides an alternative approach to large-scale optimization in machine learning.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\WI378IH3\\Cai 等 - 2020 - Optimization in Machine Learning A Distribution Space Approach.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\KU2GHV6X\\2004.html}
}

@article{charPIDinspiredInductiveBiases,
  title = {{{PID-inspired}} Inductive Biases for Deep Reinforcement Learning in Partially Observable Control Tasks},
  author = {Char, Ian and Schneider, Jeff},
  langid = {english},
  keywords = {/unread},
  file = {C:\Users\Sisyphus\Zotero\storage\4C3QRRZF\Char和Schneider - PID-Inspired Inductive Biases for Deep Reinforcement Learning in Partially Observable Control Tasks.pdf}
}

@misc{charPIDInspiredInductiveBiases2023,
  title = {{{PID-Inspired Inductive Biases}} for {{Deep Reinforcement Learning}} in {{Partially Observable Control Tasks}}},
  author = {Char, Ian and Schneider, Jeff},
  year = {2023},
  month = oct,
  number = {arXiv:2307.05891},
  eprint = {2307.05891},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.05891},
  urldate = {2024-12-10},
  abstract = {Deep reinforcement learning (RL) has shown immense potential for learning to control systems through data alone. However, one challenge deep RL faces is that the full state of the system is often not observable. When this is the case, the policy needs to leverage the history of observations to infer the current state. At the same time, differences between the training and testing environments makes it critical for the policy not to overfit to the sequence of observations it sees at training time. As such, there is an important balancing act between having the history encoder be flexible enough to extract relevant information, yet be robust to changes in the environment. To strike this balance, we look to the PID controller for inspiration. We assert the PID controller's success shows that only summing and differencing are needed to accumulate information over time for many control tasks. Following this principle, we propose two architectures for encoding history: one that directly uses PID features and another that extends these core ideas and can be used in arbitrary control tasks. When compared with prior approaches, our encoders produce policies that are often more robust and achieve better performance on a variety of tracking tasks. Going beyond tracking tasks, our policies achieve 1.7x better performance on average over previous state-of-the-art methods on a suite of locomotion control tasks.},
  archiveprefix = {arXiv},
  keywords = {/unread,Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {TLDR: This work asserts the PID controller's success shows that only summing and differencing are needed to accumulate information over time for many control tasks, and proposes two architectures for encoding history: one that directly uses PID features and another that extends these core ideas and can be used in arbitrary control tasks.},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\X96XL5QU\\Char和Schneider - 2023 - PID-Inspired Inductive Biases for Deep Reinforcement Learning in Partially Observable Control Tasks.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\5KKXFRHL\\2307.html}
}

@article{chenAcceleratedOptimizationDeep2024,
  title = {Accelerated Optimization in Deep Learning with a Proportional-Integral-Derivative Controller},
  author = {Chen, Song and Liu, Jiaxu and Wang, Pengkai and Xu, Chao and Cai, Shengze and Chu, Jian},
  year = {2024},
  month = nov,
  journal = {Nature Communications},
  volume = {15},
  number = {1},
  pages = {10263},
  issn = {2041-1723},
  doi = {10.1038/s41467-024-54451-3},
  urldate = {2024-12-01},
  langid = {english},
  annotation = {TLDR: This study develops a deterministic continuous-time optimizer called Proportional-Integral-Derivative Accelerated Optimizer (PIDAO), and provides theoretical convergence analysis of PIDAO in unconstrained (non-)convex optimizations.},
  file = {C:\Users\Sisyphus\Zotero\storage\Z3E3GF6I\Chen 等 - 2024 - Accelerated optimization in deep learning with a proportional-integral-derivative controller.pdf}
}

@misc{chenAsymptoticallyFairParticipation2023,
  title = {Asymptotically Fair Participation in Machine Learning Models: An Optimal Control Perspective},
  shorttitle = {Asymptotically Fair Participation in Machine Learning Models},
  author = {Chen, Zhuotong and Li, Qianxiao and Zhang, Zheng},
  year = {2023},
  month = nov,
  number = {arXiv:2311.10223},
  eprint = {2311.10223},
  publisher = {arXiv},
  urldate = {2024-11-22},
  abstract = {The performance of state-of-the-art machine learning models often deteriorates when testing on demographics that are under-represented in the training dataset. This problem has predominately been studied in a supervised learning setting where the data distribution is static. However, real-world applications often involve distribution shifts caused by the deployed models. For instance, the performance disparity against monitory users can lead to a high customer churn rate, thus the available data provided by active users are skewed due to the lack of minority users. This feedback effect further exacerbates the disparity among different demographic groups in future steps. To address this issue, we propose asymptotically fair participation as a condition to maintain long-term model performance over all demographic groups. In this work, we aim to address the problem of achieving asymptotically fair participation via optimal control formulation. Moreover, we design a surrogate retention system based on existing literature on evolutionary population dynamics to approximate the dynamics of distribution shifts on active user counts, from which the objective of achieving asymptotically fair participation is formulated as an optimal control problem, and the control variables are considered as the model parameters. We apply an efficient implementation of Pontryagin's maximum principle to estimate the optimal control solution. To evaluate the effectiveness of the proposed method, we design a generic simulation environment that simulates the population dynamics of the feedback effect between user retention and model performance. When we deploy the resulting models to the simulation environment, the optimal control solution accounts for long-term planning and leads to superior performance compared with existing baseline methods.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\P98TS33N\\Chen 等 - 2023 - Asymptotically Fair Participation in Machine Learning Models an Optimal Control Perspective.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\JVICLSV7\\2311.html}
}

@misc{chenGeneralControltheoreticApproach2024,
  title = {A General Control-Theoretic Approach for Reinforcement Learning: Theory and Algorithms},
  shorttitle = {A General Control-Theoretic Approach for Reinforcement Learning},
  author = {Chen, Weiqin and Squillante, Mark S. and Wu, Chai Wah and Paternain, Santiago},
  year = {2024},
  month = aug,
  number = {arXiv:2406.14753},
  eprint = {2406.14753},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.14753},
  urldate = {2024-11-20},
  abstract = {We devise a control-theoretic reinforcement learning approach to support direct learning of the optimal policy. We establish various theoretical properties of our approach, such as convergence and optimality of our control-theoretic operator, a new control-policy-parameter gradient ascent theorem, and a specific gradient ascent algorithm based on this theorem. As a representative example, we adapt our approach to a particular control-theoretic framework and empirically evaluate its performance on several classical reinforcement learning tasks, demonstrating significant improvements in solution quality, sample complexity, and running time of our control-theoretic approach over state-of-the-art baseline methods.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Methodology},
  annotation = {TLDR: This work devise a control-theoretic reinforcement learning approach to support direct learning of the optimal policy, establishing various theoretical properties of this approach, such as convergence and optimality of the authors' analog of the Bellman operator and Q-learning, and a new control-policy-variable gradient theorem.},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\TPZPLRC3\\Chen 等 - 2024 - A General Control-Theoretic Approach for Reinforcement Learning Theory and Algorithms.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\GF9WRY2F\\2406.html}
}

@misc{chengInterpolationApproximationControllability2023,
  title = {Interpolation, Approximation and Controllability of Deep Neural Networks},
  author = {Cheng, Jingpu and Li, Qianxiao and Lin, Ting and Shen, Zuowei},
  year = {2023},
  month = sep,
  number = {arXiv:2309.06015},
  eprint = {2309.06015},
  publisher = {arXiv},
  urldate = {2024-11-22},
  abstract = {We investigate the expressive power of deep residual neural networks idealized as continuous dynamical systems through control theory. Specifically, we consider two properties that arise from supervised learning, namely universal interpolation - the ability to match arbitrary input and target training samples - and the closely related notion of universal approximation - the ability to approximate input-target functional relationships via flow maps. Under the assumption of affine invariance of the control family, we give a characterisation of universal interpolation, showing that it holds for essentially any architecture with non-linearity. Furthermore, we elucidate the relationship between universal interpolation and universal approximation in the context of general control systems, showing that the two properties cannot be deduced from each other. At the same time, we identify conditions on the control family and the target function that ensures the equivalence of the two notions.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Mathematics - Dynamical Systems,Mathematics - Optimization and Control},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\ZSXNR3J4\\Cheng 等 - 2023 - Interpolation, Approximation and Controllability of Deep Neural Networks.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\NY8NPJE9\\2309.html}
}

@misc{chengLinearlyControlledLanguage2024,
  title = {Linearly Controlled Language Generation with Performative Guarantees},
  author = {Cheng, Emily and Baroni, Marco and Alonso, Carmen Amo},
  year = {2024},
  month = may,
  number = {arXiv:2405.15454},
  eprint = {2405.15454},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.15454},
  urldate = {2024-12-10},
  abstract = {The increasing prevalence of Large Language Models (LMs) in critical applications highlights the need for controlled language generation strategies that are not only computationally efficient but that also enjoy performance guarantees. To achieve this, we use a common model of concept semantics as linearly represented in an LM's latent space. In particular, we take the view that natural language generation traces a trajectory in this continuous semantic space, realized by the language model's hidden activations. This view permits a control-theoretic treatment of text generation in latent space, in which we propose a lightweight, gradient-free intervention that dynamically steers trajectories away from regions corresponding to undesired meanings. Crucially, we show that this intervention, which we compute in closed form, is guaranteed (in probability) to steer the output into the allowed region. Finally, we demonstrate on a toxicity avoidance objective that the intervention steers language away from undesired content while maintaining text quality.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {/unread,Computer Science - Computation and Language,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control},
  annotation = {TLDR: This work takes the view that natural language generation traces a trajectory in this continuous semantic space, realized by the language model's hidden activations, and proposes a lightweight, gradient-free intervention that dynamically steers trajectories away from regions corresponding to undesired meanings.},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\AUKEJYJK\\Cheng 等 - 2024 - Linearly Controlled Language Generation with Performative Guarantees.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\4TN8US32\\2405.html}
}

@misc{chenPIDControlbasedSelfhealing2024,
  title = {{{PID}} Control-Based Self-Healing to Improve the Robustness of Large Language Models},
  author = {Chen, Zhuotong and Wang, Zihu and Yang, Yifan and Li, Qianxiao and Zhang, Zheng},
  year = {2024},
  month = mar,
  number = {arXiv:2404.00828},
  eprint = {2404.00828},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2404.00828},
  urldate = {2024-11-22},
  abstract = {Despite the effectiveness of deep neural networks in numerous natural language processing applications, recent findings have exposed the vulnerability of these language models when minor perturbations are introduced. While appearing semantically indistinguishable to humans, these perturbations can significantly reduce the performance of well-trained language models, raising concerns about the reliability of deploying them in safe-critical situations. In this work, we construct a computationally efficient self-healing process to correct undesired model behavior during online inference when perturbations are applied to input data. This is formulated as a trajectory optimization problem in which the internal states of the neural network layers are automatically corrected using a PID (Proportional-Integral-Derivative) control mechanism. The P controller targets immediate state adjustments, while the I and D controllers consider past states and future dynamical trends, respectively. We leverage the geometrical properties of the training data to design effective linear PID controllers. This approach reduces the computational cost to that of using just the P controller, instead of the full PID control. Further, we introduce an analytical method for approximating the optimal control solutions, enhancing the real-time inference capabilities of this controlled system. Moreover, we conduct a theoretical error analysis of the analytic solution in a simplified setting. The proposed PID control-based self-healing is a low cost framework that improves the robustness of pre-trained large language models, whether standard or robustly trained, against a wide range of perturbations. A detailed implementation can be found in:https://github.com/zhuotongchen/PID-Control-Based-Self-Healing-to-Improve-the-Robustness-of-Large-Language-Models.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  annotation = {TLDR: The proposed PID control-based self-healing is a low cost framework that improves the robustness of pre-trained large language models, whether standard or robustly trained, against a wide range of perturbations.},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\KKLCRF2W\\Chen 等 - 2024 - PID Control-Based Self-Healing to Improve the Robustness of Large Language Models.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\TPF55GN8\\2404.html}
}

@misc{chenRobustNeuralNetworks2021,
  title = {Towards Robust Neural Networks via Close-Loop Control},
  author = {Chen, Zhuotong and Li, Qianxiao and Zhang, Zheng},
  year = {2021},
  month = apr,
  number = {arXiv:2102.01862},
  eprint = {2102.01862},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2102.01862},
  urldate = {2024-11-22},
  abstract = {Despite their success in massive engineering applications, deep neural networks are vulnerable to various perturbations due to their black-box nature. Recent study has shown that a deep neural network can misclassify the data even if the input data is perturbed by an imperceptible amount. In this paper, we address the robustness issue of neural networks by a novel close-loop control method from the perspective of dynamic systems. Instead of modifying the parameters in a fixed neural network architecture, a close-loop control process is added to generate control signals adaptively for the perturbed or corrupted data. We connect the robustness of neural networks with optimal control using the geometrical information of underlying data to design the control objective. The detailed analysis shows how the embedding manifolds of state trajectory affect error estimation of the proposed method. Our approach can simultaneously maintain the performance on clean data and improve the robustness against many types of data perturbations. It can also further improve the performance of robustly trained neural networks against different perturbations. To the best of our knowledge, this is the first work that improves the robustness of neural networks with close-loop control.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\STWWG5B6\\Chen 等 - 2021 - Towards Robust Neural Networks via Close-loop Control.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\S9NX8QD6\\2102.html}
}

@misc{chenSelfhealingRobustNeural2022,
  title = {Self-Healing Robust Neural Networks via Closed-Loop Control},
  author = {Chen, Zhuotong and Li, Qianxiao and Zhang, Zheng},
  year = {2022},
  month = jun,
  number = {arXiv:2206.12963},
  eprint = {2206.12963},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2206.12963},
  urldate = {2024-11-22},
  abstract = {Despite the wide applications of neural networks, there have been increasing concerns about their vulnerability issue. While numerous attack and defense techniques have been developed, this work investigates the robustness issue from a new angle: can we design a self-healing neural network that can automatically detect and fix the vulnerability issue by itself? A typical self-healing mechanism is the immune system of a human body. This biology-inspired idea has been used in many engineering designs but is rarely investigated in deep learning. This paper considers the post-training self-healing of a neural network, and proposes a closed-loop control formulation to automatically detect and fix the errors caused by various attacks or perturbations. We provide a margin-based analysis to explain how this formulation can improve the robustness of a classifier. To speed up the inference of the proposed self-healing network, we solve the control problem via improving the Pontryagin Maximum Principle-based solver. Lastly, we present an error estimation of the proposed framework for neural networks with nonlinear activation functions. We validate the performance on several network architectures against various perturbations. Since the self-healing method does not need a-priori information about data perturbations/attacks, it can handle a broad class of unforeseen perturbations.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  annotation = {TLDR: This work considers the post-training self-healing of a neural network, and proposes a closed-loop control formulation to automatically detect and fix the errors caused by various attacks or perturbations, and provides a margin-based analysis to explain how this formulation can improve the robustness of a classifier.},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\H49S3WQV\\Chen 等 - 2022 - Self-Healing Robust Neural Networks via Closed-Loop Control.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\87JAN8R8\\2206.html}
}

@misc{chenTransferLearningbasedPhysicsinformed2023,
  title = {Transfer Learning-Based Physics-Informed Convolutional Neural Network for Simulating Flow in Porous Media with Time-Varying Controls},
  author = {Chen, Jungang and Gildin, Eduardo and Killough, John E.},
  year = {2023},
  month = oct,
  number = {arXiv:2310.06319},
  eprint = {2310.06319},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.06319},
  urldate = {2024-11-22},
  abstract = {A physics-informed convolutional neural network is proposed to simulate two phase flow in porous media with time-varying well controls. While most of PICNNs in existing literatures worked on parameter-to-state mapping, our proposed network parameterizes the solution with time-varying controls to establish a control-to-state regression. Firstly, finite volume scheme is adopted to discretize flow equations and formulate loss function that respects mass conservation laws. Neumann boundary conditions are seamlessly incorporated into the semi-discretized equations so no additional loss term is needed. The network architecture comprises two parallel U-Net structures, with network inputs being well controls and outputs being the system states. To capture the time-dependent relationship between inputs and outputs, the network is well designed to mimic discretized state space equations. We train the network progressively for every timestep, enabling it to simultaneously predict oil pressure and water saturation at each timestep. After training the network for one timestep, we leverage transfer learning techniques to expedite the training process for subsequent timestep. The proposed model is used to simulate oil-water porous flow scenarios with varying reservoir gridblocks and aspects including computation efficiency and accuracy are compared against corresponding numerical approaches. The results underscore the potential of PICNN in effectively simulating systems with numerous grid blocks, as computation time does not scale with model dimensionality. We assess the temporal error using 10 different testing controls with variation in magnitude and another 10 with higher alternation frequency with proposed control-to-state architecture. Our observations suggest the need for a more robust and reliable model when dealing with controls that exhibit significant variations in magnitude or frequency.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computational Engineering Finance and Science,Computer Science - Machine Learning},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\YBV4Z62U\\Chen 等 - 2023 - Transfer learning-based physics-informed convolutional neural network for simulating flow in porous.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\E64Z4I3K\\2310.html}
}

@misc{daoTransformersAreSSMs2024,
  title = {Transformers Are {{SSMs}}: Generalized Models and Efficient Algorithms through Structured State Space Duality},
  shorttitle = {Transformers Are {{SSMs}}},
  author = {Dao, Tri and Gu, Albert},
  year = {2024},
  month = may,
  number = {arXiv:2405.21060},
  eprint = {2405.21060},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-06-04},
  abstract = {While Transformers have been the main architecture behind deep learning's success in language modeling, state-space models (SSMs) such as Mamba have recently been shown to match or outperform Transformers at small to medium scale. We show that these families of models are actually quite closely related, and develop a rich framework of theoretical connections between SSMs and variants of attention, connected through various decompositions of a well-studied class of structured semiseparable matrices. Our state space duality (SSD) framework allows us to design a new architecture (Mamba-2) whose core layer is an a refinement of Mamba's selective SSM that is 2-8X faster, while continuing to be competitive with Transformers on language modeling.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\8B6EBBXR\\Dao和Gu - 2024 - Transformers are SSMs Generalized Models and Efficient Algorithms Through Structured State Space Du.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\G3M8V4JF\\2405.html}
}

@misc{dongHambaSingleview3D2024,
  title = {Hamba: Single-View {{3D}} Hand Reconstruction with Graph-Guided {{Bi-scanning}} Mamba},
  shorttitle = {Hamba},
  author = {Dong, Haoye and Chharia, Aviral and Gou, Wenbo and Carrasco, Francisco Vicente and la Torre, Fernando De},
  year = {2024},
  month = jul,
  number = {arXiv:2407.09646},
  eprint = {2407.09646},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2407.09646},
  urldate = {2024-10-16},
  abstract = {3D Hand reconstruction from a single RGB image is challenging due to the articulated motion, self-occlusion, and interaction with objects. Existing SOTA methods employ attention-based transformers to learn the 3D hand pose and shape, but they fail to achieve robust and accurate performance due to insufficient modeling of joint spatial relations. To address this problem, we propose a novel graph-guided Mamba framework, named Hamba, which bridges graph learning and state space modeling. Our core idea is to reformulate Mamba's scanning into graph-guided bidirectional scanning for 3D reconstruction using a few effective tokens. This enables us to learn the joint relations and spatial sequences for enhancing the reconstruction performance. Specifically, we design a novel Graph-guided State Space (GSS) block that learns the graph-structured relations and spatial sequences of joints and uses 88.5\% fewer tokens than attention-based methods. Additionally, we integrate the state space features and the global features using a fusion module. By utilizing the GSS block and the fusion module, Hamba effectively leverages the graph-guided state space modeling features and jointly considers global and local features to improve performance. Extensive experiments on several benchmarks and in-the-wild tests demonstrate that Hamba significantly outperforms existing SOTAs, achieving the PA-MPVPE of 5.3mm and F@15mm of 0.992 on FreiHAND. Hamba is currently Rank 1 in two challenging competition leaderboards on 3D hand reconstruction. The code will be available upon acceptance. [Website](https://humansensinglab.github.io/Hamba/).},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  annotation = {TLDR: A novel graph-guided Mamba framework, named Hamba, which bridges graph learning and state space modeling, and significantly outperforms existing SOTAs, achieving the PA-MPVPE of 5.3mm and F@15mm of 0.992 on FreiHAND.},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\C3MUPCNR\\Dong 等 - 2024 - Hamba Single-view 3D Hand Reconstruction with Graph-guided Bi-Scanning Mamba.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\4ET7R9HP\\2407.html}
}

@misc{dorflerSystemsTheoryAlgorithms2024,
  title = {Towards a Systems Theory of Algorithms},
  author = {D{\"o}rfler, Florian and He, Zhiyu and Belgioioso, Giuseppe and Bolognani, Saverio and Lygeros, John and Muehlebach, Michael},
  year = {2024},
  month = apr,
  number = {arXiv:2401.14029},
  eprint = {2401.14029},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2401.14029},
  urldate = {2024-12-01},
  abstract = {Traditionally, numerical algorithms are seen as isolated pieces of code confined to an \{{\textbackslash}em in silico\} existence. However, this perspective is not appropriate for many modern computational approaches in control, learning, or optimization, wherein \{{\textbackslash}em in vivo\} algorithms interact with their environment. Examples of such \{{\textbackslash}em open algorithms\} include various real-time optimization-based control strategies, reinforcement learning, decision-making architectures, online optimization, and many more. Further, even \{{\textbackslash}em closed\} algorithms in learning or optimization are increasingly abstracted in block diagrams with interacting dynamic modules and pipelines. In this opinion paper, we state our vision on a to-be-cultivated \{{\textbackslash}em systems theory of algorithms\} and argue in favor of viewing algorithms as open dynamical systems interacting with other algorithms, physical systems, humans, or databases. Remarkably, the manifold tools developed under the umbrella of systems theory are well suited for addressing a range of challenges in the algorithmic domain. We survey various instances where the principles of algorithmic systems theory are being developed and outline pertinent modeling, analysis, and design challenges.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control,Mathematics - Optimization and Control},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\L2CZ3MJ6\\Dörfler 等 - 2024 - Towards a Systems Theory of Algorithms.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\Y3346VYW\\2401.html}
}

@misc{eMeanfieldOptimalControl2018,
  title = {A Mean-Field Optimal Control Formulation of Deep Learning},
  author = {E, Weinan and Han, Jiequn and Li, Qianxiao},
  year = {2018},
  month = jul,
  number = {arXiv:1807.01083},
  eprint = {1807.01083},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1807.01083},
  urldate = {2024-11-22},
  abstract = {Recent work linking deep neural networks and dynamical systems opened up new avenues to analyze deep learning. In particular, it is observed that new insights can be obtained by recasting deep learning as an optimal control problem on difference or differential equations. However, the mathematical aspects of such a formulation have not been systematically explored. This paper introduces the mathematical formulation of the population risk minimization problem in deep learning as a mean-field optimal control problem. Mirroring the development of classical optimal control, we state and prove optimality conditions of both the Hamilton-Jacobi-Bellman type and the Pontryagin type. These mean-field results reflect the probabilistic nature of the learning problem. In addition, by appealing to the mean-field Pontryagin's maximum principle, we establish some quantitative relationships between population and empirical learning problems. This serves to establish a mathematical foundation for investigating the algorithmic and theoretical connections between optimal control and deep learning.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\N9SK8W6Q\\E 等 - 2018 - A Mean-Field Optimal Control Formulation of Deep Learning.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\S7WMV6SM\\1807.html}
}

@misc{feiRealtimeProgressiveLearning2023,
  title = {Real-Time Progressive Learning: Accumulate Knowledge from Control with Neural-Network-Based Selective Memory},
  shorttitle = {Real-Time Progressive Learning},
  author = {Fei, Yiming and Li, Jiangang and Li, Yanan},
  year = {2023},
  month = nov,
  number = {arXiv:2308.04223},
  eprint = {2308.04223},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2308.04223},
  urldate = {2024-11-22},
  abstract = {Memory, as the basis of learning, determines the storage, update and forgetting of knowledge and further determines the efficiency of learning. Featured with the mechanism of memory, a radial basis function neural network based learning control scheme named real-time progressive learning (RTPL) is proposed to learn the unknown dynamics of the system with guaranteed stability and closed-loop performance. Instead of the Lyapunov-based weight update law of conventional neural network learning control (NNLC), which mainly concentrates on stability and control performance, RTPL employs the selective memory recursive least squares (SMRLS) algorithm to update the weights of the neural network and achieves the following merits: 1) improved learning speed without filtering, 2) robustness to hyperparameter setting of neural networks, 3) good generalization ability, i.e., reuse of learned knowledge in different tasks, and 4) guaranteed learning performance under parameter perturbation. Moreover, RTPL realizes continuous accumulation of knowledge as a result of its reasonably allocated memory while NNLC may gradually forget knowledge that it has learned. Corresponding theoretical analysis and simulation studies demonstrate the effectiveness of RTPL.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Neural and Evolutionary Computing,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control},
  annotation = {TLDR: The proposed real-time progressive learning scheme achieves the following merits over the classical ANC: guaranteed learning capability under low-level persistent excitation (PE), improved learning performance (learning speed, accuracy and generalization capability), and low gain requirement ensuring robustness of RTPL in practical applications.},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\MWZG4PSQ\\Fei 等 - 2023 - Real-Time Progressive Learning Accumulate Knowledge from Control with Neural-Network-Based Selectiv.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\GFZ7BM2N\\2308.html}
}

@article{guMambaLineartimeSequence,
  title = {Mamba: Linear-Time Sequence Modeling with Selective State Spaces},
  author = {Gu, Albert and Dao, Tri},
  abstract = {Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on the Transformer architecture and its core attention module. Many subquadratic-time architectures such as linear attention, gated convolution and recurrent models, and structured state space models (SSMs) have been developed to address Transformers' computational inefficiency on long sequences, but they have not performed as well as attention on important modalities such as language. We identify that a key weakness of such models is their inability to perform content-based reasoning, and make several improvements. First, simply letting the SSM parameters be functions of the input addresses their weakness with discrete modalities, allowing the model to selectively propagate or forget information along the sequence length dimension depending on the current token. Second, even though this change prevents the use of efficient convolutions, we design a hardware-aware parallel algorithm in recurrent mode. We integrate these selective SSMs into a simplified end-to-end neural network architecture without attention or even MLP blocks (Mamba). Mamba enjoys fast inference (5{\texttimes} higher throughput than Transformers) and linear scaling in sequence length, and its performance improves on real data up to million-length sequences. As a general sequence model backbone, Mamba achieves state-of-the-art performance across several modalities such as language, audio, and genomics. On language modeling, our Mamba-3B model outperforms Transformers of the same size and matches Transformers twice its size, both in pretraining and downstream evaluation.},
  langid = {english},
  file = {C:\Users\Sisyphus\Zotero\storage\QTWCDLQZ\Gu 和 Dao - Mamba Linear-Time Sequence Modeling with Selectiv.pdf}
}

@misc{hanUtilityKoopmanOperator2023,
  title = {On the Utility of Koopman Operator Theory in Learning Dexterous Manipulation Skills},
  author = {Han, Yunhai and Xie, Mandy and Zhao, Ye and Ravichandar, Harish},
  year = {2023},
  month = aug,
  number = {arXiv:2303.13446},
  eprint = {2303.13446},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2303.13446},
  urldate = {2024-11-20},
  abstract = {Despite impressive dexterous manipulation capabilities enabled by learning-based approaches, we are yet to witness widespread adoption beyond well-resourced laboratories. This is likely due to practical limitations, such as significant computational burden, inscrutable learned behaviors, sensitivity to initialization, and the considerable technical expertise required for implementation. In this work, we investigate the utility of Koopman operator theory in alleviating these limitations. Koopman operators are simple yet powerful control-theoretic structures to represent complex nonlinear dynamics as linear systems in higher dimensions. Motivated by the fact that complex nonlinear dynamics underlie dexterous manipulation, we develop a Koopman operator-based imitation learning framework to learn the desired motions of both the robotic hand and the object simultaneously. We show that Koopman operators are surprisingly effective for dexterous manipulation and offer a number of unique benefits. Notably, policies can be learned analytically, drastically reducing computation burden and eliminating sensitivity to initialization and the need for painstaking hyperparameter optimization. Our experiments reveal that a Koopman operator-based approach can perform comparably to state-of-the-art imitation learning algorithms in terms of success rate and sample efficiency, while being an order of magnitude faster. Policy videos can be viewed at https://sites.google.com/view/kodex-corl.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics},
  annotation = {TLDR: It is shown that a Koopman operator-based approach can perform comparably to state-of-the-art imitation learning algorithms in terms of success rate and sample efficiency, while being an order of magnitude faster.},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\9Y89VAXD\\Han 等 - 2023 - On the Utility of Koopman Operator Theory in Learning Dexterous Manipulation Skills.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\P827WLDC\\2303.html}
}

@misc{heDeepResidualLearning2015,
  title = {Deep Residual Learning for Image Recognition},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  year = {2015},
  month = dec,
  number = {arXiv:1512.03385},
  eprint = {1512.03385},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1512.03385},
  urldate = {2023-04-28},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\Z6YNBGIS\\He 等 - 2015 - Deep Residual Learning for Image Recognition.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\C9XEGVGZ\\1512.html}
}

@misc{huchetteWhenDeepLearning2023,
  title = {When Deep Learning Meets Polyhedral Theory: A Survey},
  shorttitle = {When Deep Learning Meets Polyhedral Theory},
  author = {Huchette, Joey and Mu{\~n}oz, Gonzalo and Serra, Thiago and Tsay, Calvin},
  year = {2023},
  month = aug,
  number = {arXiv:2305.00241},
  eprint = {2305.00241},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2305.00241},
  urldate = {2024-11-20},
  abstract = {In the past decade, deep learning became the prevalent methodology for predictive modeling thanks to the remarkable accuracy of deep neural networks in tasks such as computer vision and natural language processing. Meanwhile, the structure of neural networks converged back to simpler representations based on piecewise constant and piecewise linear functions such as the Rectified Linear Unit (ReLU), which became the most commonly used type of activation function in neural networks. That made certain types of network structure \${\textbackslash}unicode\{x2014\}\$such as the typical fully-connected feedforward neural network\${\textbackslash}unicode\{x2014\}\$ amenable to analysis through polyhedral theory and to the application of methodologies such as Linear Programming (LP) and Mixed-Integer Linear Programming (MILP) for a variety of purposes. In this paper, we survey the main topics emerging from this fast-paced area of work, which bring a fresh perspective to understanding neural networks in more detail as well as to applying linear optimization techniques to train, verify, and reduce the size of such networks.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control},
  annotation = {TLDR: The main topics emerging from this fast-paced area of work, which bring a fresh perspective to understanding neural networks in more detail as well as to applying linear optimization techniques to train, verify, and reduce the size of such networks are surveyed.},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\IZ94I4UE\\Huchette 等 - 2023 - When Deep Learning Meets Polyhedral Theory A Survey.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\2HQE2ME6\\2305.html}
}

@misc{jiangForwardInverseApproximation2023,
  title = {Forward and Inverse Approximation Theory for Linear Temporal Convolutional Networks},
  author = {Jiang, Haotian and Li, Qianxiao},
  year = {2023},
  month = may,
  number = {arXiv:2305.18478},
  eprint = {2305.18478},
  publisher = {arXiv},
  urldate = {2024-11-22},
  abstract = {We present a theoretical analysis of the approximation properties of convolutional architectures when applied to the modeling of temporal sequences. Specifically, we prove an approximation rate estimate (Jackson-type result) and an inverse approximation theorem (Bernstein-type result), which together provide a comprehensive characterization of the types of sequential relationships that can be efficiently captured by a temporal convolutional architecture. The rate estimate improves upon a previous result via the introduction of a refined complexity measure, whereas the inverse approximation theorem is new.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\N4J62RS7\\Jiang和Li - 2023 - Forward and Inverse Approximation Theory for Linear Temporal Convolutional Networks.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\UJFMIWRI\\2305.html}
}

@misc{konDirectLearningParametervarying2023,
  title = {Direct Learning for Parameter-Varying Feedforward Control: A Neural-Network Approach},
  shorttitle = {Direct Learning for Parameter-Varying Feedforward Control},
  author = {Kon, Johan and van de Wijdeven, Jeroen and Bruijnen, Dennis and T{\'o}th, Roland and Heertjes, Marcel and Oomen, Tom},
  year = {2023},
  month = sep,
  number = {arXiv:2309.12722},
  eprint = {2309.12722},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.12722},
  urldate = {2024-11-22},
  abstract = {The performance of a feedforward controller is primarily determined by the extent to which it can capture the relevant dynamics of a system. The aim of this paper is to develop an input-output linear parameter-varying (LPV) feedforward parameterization and a corresponding data-driven estimation method in which the dependency of the coefficients on the scheduling signal are learned by a neural network. The use of a neural network enables the parameterization to compensate a wide class of constant relative degree LPV systems. Efficient optimization of the neural-network-based controller is achieved through a Levenberg-Marquardt approach with analytic gradients and a pseudolinear approach generalizing Sanathanan-Koerner to the LPV case. The performance of the developed feedforward learning method is validated in a simulation study of an LPV system showing excellent performance.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\IDEE59TU\\Kon 等 - 2023 - Direct Learning for Parameter-Varying Feedforward Control A Neural-Network Approach.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\4KLJ8H5Q\\2309.html}
}

@misc{kongAligningLargeLanguage2024,
  title = {Aligning Large Language Models with Representation Editing: A Control Perspective},
  shorttitle = {Aligning Large Language Models with Representation Editing},
  author = {Kong, Lingkai and Wang, Haorui and Mu, Wenhao and Du, Yuanqi and Zhuang, Yuchen and Zhou, Yifei and Song, Yue and Zhang, Rongzhi and Wang, Kai and Zhang, Chao},
  year = {2024},
  month = nov,
  number = {arXiv:2406.05954},
  eprint = {2406.05954},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.05954},
  urldate = {2024-12-10},
  abstract = {Aligning large language models (LLMs) with human objectives is crucial for real-world applications. However, fine-tuning LLMs for alignment often suffers from unstable training and requires substantial computing resources. Test-time alignment techniques, such as prompting and guided decoding, do not modify the underlying model, and their performance remains dependent on the original model's capabilities. To address these challenges, we propose aligning LLMs through representation editing. The core of our method is to view a pre-trained autoregressive LLM as a discrete-time stochastic dynamical system. To achieve alignment for specific objectives, we introduce external control signals into the state space of this language dynamical system. We train a value function directly on the hidden states according to the Bellman equation, enabling gradient-based optimization to obtain the optimal control signals at test time. Our experiments demonstrate that our method outperforms existing test-time alignment techniques while requiring significantly fewer resources compared to fine-tuning methods. Our code is available at https://github.com/Lingkai-Kong/RE-Control.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {/unread,Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control},
  annotation = {TLDR: The core of the method is to view a pre-trained autoregressive LLM as a discrete-time stochastic dynamical system and train a value function directly on the hidden states according to the Bellman equation, enabling gradient-based optimization to obtain the optimal control signals at test time.},
  file = {C:\Users\Sisyphus\Zotero\storage\D7WVDC5B\Kong 等 - 2024 - Aligning Large Language Models with Representation Editing A Control Perspective.pdf}
}

@article{liDeepLearningDynamical2022,
  title = {Deep Learning via Dynamical Systems: An Approximation Perspective},
  shorttitle = {Deep Learning via Dynamical Systems},
  author = {Li, Qianxiao and Lin, Ting and Shen, Zuowei},
  year = {2022},
  month = apr,
  journal = {Journal of the European Mathematical Society},
  volume = {25},
  number = {5},
  pages = {1671--1709},
  issn = {1435-9855, 1435-9863},
  doi = {10.4171/jems/1221},
  urldate = {2024-11-27},
  abstract = {We build on the dynamical systems approach to deep learning, where deep residual networks are idealized as continuous-time dynamical systems, from the approximation perspective. In particular, we establish general sufficient conditions for universal approximation using continuous-time deep residual networks, which can also be understood as approximation theories in                                L{\textasciicircum}p                              using flow maps of dynamical systems. In specific cases, rates of approximation in terms of the time horizon are also established. Overall, these results reveal that composition function approximation through flow maps presents a new paradigm in approximation theory and contributes to building a useful mathematical framework to investigate deep learning.},
  langid = {english},
  annotation = {TLDR: The results reveal that composition function approximation through flow maps present a new paradigm in approximation theory and contributes to building a useful mathematical framework to investigate deep learning.},
  file = {C:\Users\Sisyphus\Zotero\storage\WVWYPC5J\Li 等 - 2022 - Deep learning via dynamical systems An approximation perspective.pdf}
}

@misc{liDeepNeuralNetwork2022,
  title = {Deep Neural Network Approximation of Invariant Functions through Dynamical Systems},
  author = {Li, Qianxiao and Lin, Ting and Shen, Zuowei},
  year = {2022},
  month = aug,
  number = {arXiv:2208.08707},
  eprint = {2208.08707},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2208.08707},
  urldate = {2024-11-22},
  abstract = {We study the approximation of functions which are invariant with respect to certain permutations of the input indices using flow maps of dynamical systems. Such invariant functions includes the much studied translation-invariant ones involving image tasks, but also encompasses many permutation-invariant functions that finds emerging applications in science and engineering. We prove sufficient conditions for universal approximation of these functions by a controlled equivariant dynamical system, which can be viewed as a general abstraction of deep residual networks with symmetry constraints. These results not only imply the universal approximation for a variety of commonly employed neural network architectures for symmetric function approximation, but also guide the design of architectures with approximation guarantees for applications involving new symmetry requirements.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Mathematics - Dynamical Systems,Mathematics - Optimization and Control},
  annotation = {TLDR: It is proved sufficient conditions for universal approximation of functions which are invariant with respect to certain permutations of the input indices by a controlled equivariant dynamical system, which can be viewed as a general abstraction of deep residual networks with symmetry constraints.},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\AZ6HU5U8\\Li 等 - 2022 - Deep Neural Network Approximation of Invariant Functions through Dynamical Systems.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\JB948VDP\\2208.html}
}

@misc{liMaximumPrincipleBased2018,
  title = {Maximum Principle Based Algorithms for Deep Learning},
  author = {Li, Qianxiao and Chen, Long and Tai, Cheng and E, Weinan},
  year = {2018},
  month = jun,
  number = {arXiv:1710.09513},
  eprint = {1710.09513},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1710.09513},
  urldate = {2024-11-22},
  abstract = {The continuous dynamical system approach to deep learning is explored in order to devise alternative frameworks for training algorithms. Training is recast as a control problem and this allows us to formulate necessary optimality conditions in continuous time using the Pontryagin's maximum principle (PMP). A modification of the method of successive approximations is then used to solve the PMP, giving rise to an alternative training algorithm for deep learning. This approach has the advantage that rigorous error estimates and convergence results can be established. We also show that it may avoid some pitfalls of gradient-based methods, such as slow convergence on flat landscapes near saddle points. Furthermore, we demonstrate that it obtains favorable initial convergence rate per-iteration, provided Hamiltonian maximization can be efficiently carried out - a step which is still in need of improvement. Overall, the approach opens up new avenues to attack problems associated with deep learning, such as trapping in slow manifolds and inapplicability of gradient-based methods for discrete trainable variables.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\HS8ZTE46\\Li 等 - 2018 - Maximum Principle Based Algorithms for Deep Learning.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\PC2BYX5B\\1710.html}
}

@misc{liOptimalControlApproach2018,
  title = {An Optimal Control Approach to Deep Learning and Applications to Discrete-Weight Neural Networks},
  author = {Li, Qianxiao and Hao, Shuji},
  year = {2018},
  month = jun,
  number = {arXiv:1803.01299},
  eprint = {1803.01299},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1803.01299},
  urldate = {2024-11-22},
  abstract = {Deep learning is formulated as a discrete-time optimal control problem. This allows one to characterize necessary conditions for optimality and develop training algorithms that do not rely on gradients with respect to the trainable parameters. In particular, we introduce the discrete-time method of successive approximations (MSA), which is based on the Pontryagin's maximum principle, for training neural networks. A rigorous error estimate for the discrete MSA is obtained, which sheds light on its dynamics and the means to stabilize the algorithm. The developed methods are applied to train, in a rather principled way, neural networks with weights that are constrained to take values in a discrete set. We obtain competitive performance and interestingly, very sparse weights in the case of ternary networks, which may be useful in model deployment in low-memory devices.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\YXBFBN9G\\Li和Hao - 2018 - An Optimal Control Approach to Deep Learning and Applications to Discrete-Weight Neural Networks.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\UDDZMT8K\\1803.html}
}

@misc{liStochasticModifiedEquations2017,
  title = {Stochastic Modified Equations and Adaptive Stochastic Gradient Algorithms},
  author = {Li, Qianxiao and Tai, Cheng and E, Weinan},
  year = {2017},
  month = jun,
  number = {arXiv:1511.06251},
  eprint = {1511.06251},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1511.06251},
  urldate = {2024-11-22},
  abstract = {We develop the method of stochastic modified equations (SME), in which stochastic gradient algorithms are approximated in the weak sense by continuous-time stochastic differential equations. We exploit the continuous formulation together with optimal control theory to derive novel adaptive hyper-parameter adjustment policies. Our algorithms have competitive performance with the added benefit of being robust to varying models and datasets. This provides a general methodology for the analysis and design of stochastic gradient algorithms.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\DSJTBMQX\\Li 等 - 2017 - Stochastic modified equations and adaptive stochastic gradient algorithms.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\JHZ8S5EY\\1511.html}
}

@misc{liStochasticModifiedEquations2018,
  title = {Stochastic Modified Equations and Dynamics of Stochastic Gradient Algorithms {{I}}: Mathematical Foundations},
  shorttitle = {Stochastic Modified Equations and Dynamics of Stochastic Gradient Algorithms {{I}}},
  author = {Li, Qianxiao and Tai, Cheng and E, Weinan},
  year = {2018},
  month = nov,
  number = {arXiv:1811.01558},
  eprint = {1811.01558},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1811.01558},
  urldate = {2024-11-22},
  abstract = {We develop the mathematical foundations of the stochastic modified equations (SME) framework for analyzing the dynamics of stochastic gradient algorithms, where the latter is approximated by a class of stochastic differential equations with small noise parameters. We prove that this approximation can be understood mathematically as an weak approximation, which leads to a number of precise and useful results on the approximations of stochastic gradient descent (SGD), momentum SGD and stochastic Nesterov's accelerated gradient method in the general setting of stochastic objectives. We also demonstrate through explicit calculations that this continuous-time approach can uncover important analytical insights into the stochastic gradient algorithms under consideration that may not be easy to obtain in a purely discrete-time setting.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\EA6FEZ9F\\Li 等 - 2018 - Stochastic Modified Equations and Dynamics of Stochastic Gradient Algorithms I Mathematical Foundat.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\QDLH8YYH\\1811.html}
}

@misc{liuDeepLearningTheory2019,
  title = {Deep Learning Theory Review: An Optimal Control and Dynamical Systems Perspective},
  shorttitle = {Deep Learning Theory Review},
  author = {Liu, Guan-Horng and Theodorou, Evangelos A.},
  year = {2019},
  month = sep,
  number = {arXiv:1908.10920},
  eprint = {1908.10920},
  publisher = {arXiv},
  urldate = {2024-11-22},
  abstract = {Attempts from different disciplines to provide a fundamental understanding of deep learning have advanced rapidly in recent years, yet a unified framework remains relatively limited. In this article, we provide one possible way to align existing branches of deep learning theory through the lens of dynamical system and optimal control. By viewing deep neural networks as discrete-time nonlinear dynamical systems, we can analyze how information propagates through layers using mean field theory. When optimization algorithms are further recast as controllers, the ultimate goal of training processes can be formulated as an optimal control problem. In addition, we can reveal convergence and generalization properties by studying the stochastic dynamics of optimization algorithms. This viewpoint features a wide range of theoretical study from information bottleneck to statistical physics. It also provides a principled way for hyper-parameter tuning when optimal control theory is introduced. Our framework fits nicely with supervised learning and can be extended to other learning problems, such as Bayesian learning, adversarial training, and specific forms of meta learning, without efforts. The review aims to shed lights on the importance of dynamics and optimal control when developing deep learning theory.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control,Statistics - Machine Learning},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\V96UQ3CB\\Liu和Theodorou - 2019 - Deep Learning Theory Review An Optimal Control and Dynamical Systems Perspective.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\FNY995C5\\1908.html}
}

@misc{liuMeaningsFeelingsLarge2024,
  title = {Meanings and Feelings of Large Language Models: Observability of Latent States in Generative {{AI}}},
  shorttitle = {Meanings and Feelings of Large Language Models},
  author = {Liu, Tian Yu and Soatto, Stefano and Marchi, Matteo and Chaudhari, Pratik and Tabuada, Paulo},
  year = {2024},
  month = may,
  number = {arXiv:2405.14061},
  eprint = {2405.14061},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.14061},
  urldate = {2024-12-10},
  abstract = {We tackle the question of whether Large Language Models (LLMs), viewed as dynamical systems with state evolving in the embedding space of symbolic tokens, are observable. That is, whether there exist multiple 'mental' state trajectories that yield the same sequence of generated tokens, or sequences that belong to the same Nerode equivalence class ('meaning'). If not observable, mental state trajectories ('experiences') evoked by an input ('perception') or by feedback from the model's own state ('thoughts') could remain self-contained and evolve unbeknown to the user while being potentially accessible to the model provider. Such "self-contained experiences evoked by perception or thought" are akin to what the American Psychological Association (APA) defines as 'feelings'. Beyond the lexical curiosity, we show that current LLMs implemented by autoregressive Transformers cannot have 'feelings' according to this definition: The set of state trajectories indistinguishable from the tokenized output is a singleton. But if there are 'system prompts' not visible to the user, then the set of indistinguishable trajectories becomes non-trivial, and there can be multiple state trajectories that yield the same verbalized output. We prove these claims analytically, and show examples of modifications to standard LLMs that engender such 'feelings.' Our analysis sheds light on possible designs that would enable a model to perform non-trivial computation that is not visible to the user, as well as on controls that the provider of services using the model could take to prevent unintended behavior.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {/unread,Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\44XM63IV\\Liu 等 - 2024 - Meanings and Feelings of Large Language Models Observability of Latent States in Generative AI.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\VYQHMK2Y\\2405.html}
}

@misc{markowichPDEModelsDeep2024,
  title = {{{PDE}} Models for Deep Neural Networks: Learning Theory, Calculus of Variations and Optimal Control},
  shorttitle = {{{PDE}} Models for Deep Neural Networks},
  author = {Markowich, Peter and Portaro, Simone},
  year = {2024},
  month = nov,
  number = {arXiv:2411.06290},
  eprint = {2411.06290},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2411.06290},
  urldate = {2024-11-22},
  abstract = {We propose a partial differential-integral equation (PDE) framework for deep neural networks (DNNs) and their associated learning problem by taking the continuum limits of both network width and depth. The proposed model captures the complex interactions among hidden nodes, overcoming limitations of traditional discrete and ordinary differential equation (ODE)-based models. We explore the well-posedness of the forward propagation problem, analyze the existence and properties of minimizers for the learning task, and provide a detailed examination of necessary and sufficient conditions for the existence of critical points. Controllability and optimality conditions for the learning task with its associated PDE forward problem are established using variational calculus, the Pontryagin Maximum Principle, and the Hamilton-Jacobi-Bellman equation, framing the deep learning process as a PDE-constrained optimization problem. In this context, we prove the existence of viscosity solutions for the latter and we establish optimal feedback controls based on the value functional. This approach facilitates the development of new network architectures and numerical methods that improve upon traditional layer-by-layer gradient descent techniques by introducing forward-backward PDE discretization. The paper provides a mathematical foundation for connecting neural networks, PDE theory, variational analysis, and optimal control, partly building on and extending the results of {\textbackslash}cite\{liu2020selection\}, where the main focus was the analysis of the forward evolution. By integrating these fields, we offer a robust framework that enhances deep learning models' stability, efficiency, and interpretability.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Mathematics - Optimization and Control},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\YQWCA9RF\\Markowich和Portaro - 2024 - PDE Models for Deep Neural Networks Learning Theory, Calculus of Variations and Optimal Control.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\9VBI8ANC\\2411.html}
}

@misc{nguyenPhysicsconstrainedTaylorNeural2024,
  title = {Physics-Constrained Taylor Neural Networks for Learning and Control of Dynamical Systems},
  author = {Nguyen, Nam T. and Tique, Juan C.},
  year = {2024},
  month = oct,
  number = {arXiv:2410.02258},
  eprint = {2410.02258},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.02258},
  urldate = {2024-11-22},
  abstract = {Data-driven approaches are increasingly popular for identifying dynamical systems due to improved accuracy and availability of sensor data. However, relying solely on data for identification does not guarantee that the identified systems will maintain their physical properties or that the predicted models will generalize well. In this paper, we propose a novel method for system identification by integrating a neural network as the first-order derivative of a Taylor series expansion instead of learning a dynamical function directly. This approach, called Monotonic Taylor Neural Networks (MTNN), aims to ensure monotonic properties of dynamical systems by constraining the conditions for the output of the neural networks model to be either always non-positive or non-negative. These conditions are constructed in two ways: by designing a new neural network architecture or by regularizing the loss function for training. The proposed method demonstrates better performance compared to methods without constraints on the monotonic properties of the systems when tested with experimental data from two real-world systems, including HVAC and TCLab. Furthermore, MTNN shows good performance in an actual control application when using a model predictive controller for a nonlinear MIMO system, illustrating the practical applications of this method.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control},
  annotation = {TLDR: This approach, called Monotonic Taylor Neural Networks (MTNN), aims to ensure monotonic properties of dynamical systems by constraining the conditions for the output of the neural networks model to be either always non-positive or non-negative.},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\FUFDL5G7\\Nguyen和Tique - 2024 - Physics-Constrained Taylor Neural Networks for Learning and Control of Dynamical Systems.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\4B8L3QLU\\2410.html}
}

@misc{nguyenPIDformerTransformerMeets2024,
  title = {{{PIDformer}}: Transformer Meets Control Theory},
  shorttitle = {{{PIDformer}}},
  author = {Nguyen, Tam and Uribe, C{\'e}sar A. and Nguyen, Tan M. and Baraniuk, Richard G.},
  year = {2024},
  month = feb,
  number = {arXiv:2402.15989},
  eprint = {2402.15989},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.15989},
  urldate = {2024-11-11},
  abstract = {In this work, we address two main shortcomings of transformer architectures: input corruption and rank collapse in their output representation. We unveil self-attention as an autonomous state-space model that inherently promotes smoothness in its solutions, leading to lower-rank outputs and diminished representation capacity. Moreover, the steady-state solution of the model is sensitive to input perturbations. We incorporate a Proportional-Integral-Derivative (PID) closed-loop feedback control system with a reference point into the model to improve robustness and representation capacity. This integration aims to preserve high-frequency details while bolstering model stability, rendering it more noise-resilient. The resulting controlled state-space model is theoretically proven robust and adept at addressing the rank collapse. Motivated by this control framework, we derive a novel class of transformers, PID-controlled Transformer (PIDformer), aimed at improving robustness and mitigating the rank-collapse issue inherent in softmax transformers. We empirically evaluate the model for advantages and robustness against baseline transformers across various practical tasks, including object classification, image segmentation, and language modeling.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control},
  annotation = {TLDR: A novel class of transformers is derived, PID-controlled Transformer (PIDformer), aimed at improving robustness and mitigating the rank-collapse issue inherent in softmax transformers.},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\AFNA69M5\\Nguyen 等 - 2024 - PIDformer Transformer Meets Control Theory.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\ZYCD2MSZ\\2402.html}
}

@misc{renUnifyingBackpropagationForwardforward2024,
  title = {Unifying Back-Propagation and Forward-Forward Algorithms through Model Predictive Control},
  author = {Ren, Lianhai and Li, Qianxiao},
  year = {2024},
  month = sep,
  number = {arXiv:2409.19561},
  eprint = {2409.19561},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2409.19561},
  urldate = {2024-12-01},
  abstract = {We introduce a Model Predictive Control (MPC) framework for training deep neural networks, systematically unifying the Back-Propagation (BP) and Forward-Forward (FF) algorithms. At the same time, it gives rise to a range of intermediate training algorithms with varying look-forward horizons, leading to a performance-efficiency trade-off. We perform a precise analysis of this trade-off on a deep linear network, where the qualitative conclusions carry over to general networks. Based on our analysis, we propose a principled method to choose the optimization horizon based on given objectives and model specifications. Numerical results on various models and tasks demonstrate the versatility of our method.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control},
  annotation = {TLDR: This work proposes a principled method to choose the optimization horizon based on given objectives and model specifications, and performs a precise analysis of this trade-off on a deep linear network.},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\85UNWD2R\\Ren和Li - 2024 - Unifying back-propagation and forward-forward algorithms through model predictive control.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\5T8T7WTA\\2409.html}
}

@misc{soattoTamingAIBots2023,
  title = {Taming {{AI}} Bots: Controllability of Neural States in Large Language Models},
  shorttitle = {Taming {{AI}} Bots},
  author = {Soatto, Stefano and Tabuada, Paulo and Chaudhari, Pratik and Liu, Tian Yu},
  year = {2023},
  month = may,
  number = {arXiv:2305.18449},
  eprint = {2305.18449},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2305.18449},
  urldate = {2024-12-10},
  abstract = {We tackle the question of whether an agent can, by suitable choice of prompts, control an AI bot to any state. To that end, we first introduce a formal definition of ``meaning'' that is amenable to analysis. Then, we characterize ``meaningful data'' on which large language models (LLMs) are ostensibly trained, and ``well-trained LLMs'' through conditions that are largely met by today's LLMs. While a well-trained LLM constructs an embedding space of meanings that is Euclidean, meanings themselves do not form a vector (linear) subspace, but rather a quotient space within. We then characterize the subset of meanings that can be reached by the state of the LLMs for some input prompt, and show that a well-trained bot can reach any meaning albeit with small probability. We then introduce a stronger notion of controllability as \{{\textbackslash}em almost certain reachability\}, and show that, when restricted to the space of meanings, an AI bot is controllable. We do so after introducing a functional characterization of attentive AI bots, and finally derive necessary and sufficient conditions for controllability. The fact that AI bots are controllable means that an adversary could steer them towards any state. However, the sampling process can be designed to counteract adverse actions and avoid reaching undesirable regions of state space before their boundary is crossed.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {/unread,Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control},
  annotation = {TLDR: This work introduces a formal definition of ``meaning'' that is amenable to analysis, and characterize the subset of meanings that can be reached by the state of the LLMs for some input prompt, and shows that a well-trained bot can reach any meaning albeit with small probability.},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\TK9PHCF4\\Soatto 等 - 2023 - Taming AI Bots Controllability of Neural States in Large Language Models.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\BZ7686MT\\2305.html}
}

@misc{tiezziStatespaceModelingLong2024,
  title = {State-Space Modeling in Long Sequence Processing: A Survey on Recurrence in the Transformer Era},
  shorttitle = {State-Space Modeling in Long Sequence Processing},
  author = {Tiezzi, Matteo and Casoni, Michele and Betti, Alessandro and Gori, Marco and Melacci, Stefano},
  year = {2024},
  month = jun,
  number = {arXiv:2406.09062},
  eprint = {2406.09062},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.09062},
  urldate = {2024-12-01},
  abstract = {Effectively learning from sequential data is a longstanding goal of Artificial Intelligence, especially in the case of long sequences. From the dawn of Machine Learning, several researchers engaged in the search of algorithms and architectures capable of processing sequences of patterns, retaining information about the past inputs while still leveraging the upcoming data, without losing precious long-term dependencies and correlations. While such an ultimate goal is inspired by the human hallmark of continuous real-time processing of sensory information, several solutions simplified the learning paradigm by artificially limiting the processed context or dealing with sequences of limited length, given in advance. These solutions were further emphasized by the large ubiquity of Transformers, that have initially shaded the role of Recurrent Neural Nets. However, recurrent networks are facing a strong recent revival due to the growing popularity of (deep) State-Space models and novel instances of large-context Transformers, which are both based on recurrent computations to go beyond several limits of currently ubiquitous technologies. In fact, the fast development of Large Language Models enhanced the interest in efficient solutions to process data over time. This survey provides an in-depth summary of the latest approaches that are based on recurrent models for sequential data processing. A complete taxonomy over the latest trends in architectural and algorithmic solutions is reported and discussed, guiding researchers in this appealing research field. The emerging picture suggests that there is room for thinking of novel routes, constituted by learning algorithms which depart from the standard Backpropagation Through Time, towards a more realistic scenario where patterns are effectively processed online, leveraging local-forward computations, opening to further research on this topic.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning},
  annotation = {TLDR: This survey provides an in-depth summary of the latest approaches that are based on recurrent models for sequential data processing, suggesting that there is room for thinking of novel routes, constituted by learning algorithms which depart from the standard Backpropagation Through Time, towards a more realistic scenario where patterns are effectively processed online, leveraging local-forward computations.},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\3GH6QJ7V\\Tiezzi 等 - 2024 - State-Space Modeling in Long Sequence Processing A Survey on Recurrence in the Transformer Era.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\FKL3SKK6\\2406.html}
}

@misc{wangStateSpaceModel2024,
  title = {State Space Model for New-Generation Network Alternative to Transformers: A Survey},
  shorttitle = {State Space Model for New-Generation Network Alternative to Transformers},
  author = {Wang, Xiao and Wang, Shiao and Ding, Yuhe and Li, Yuehang and Wu, Wentao and Rong, Yao and Kong, Weizhe and Huang, Ju and Li, Shihao and Yang, Haoxiang and Wang, Ziwen and Jiang, Bo and Li, Chenglong and Wang, Yaowei and Tian, Yonghong and Tang, Jin},
  year = {2024},
  month = apr,
  number = {arXiv:2404.09516},
  eprint = {2404.09516},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2404.09516},
  urldate = {2024-12-01},
  abstract = {In the post-deep learning era, the Transformer architecture has demonstrated its powerful performance across pre-trained big models and various downstream tasks. However, the enormous computational demands of this architecture have deterred many researchers. To further reduce the complexity of attention models, numerous efforts have been made to design more efficient methods. Among them, the State Space Model (SSM), as a possible replacement for the self-attention based Transformer model, has drawn more and more attention in recent years. In this paper, we give the first comprehensive review of these works and also provide experimental comparisons and analysis to better demonstrate the features and advantages of SSM. Specifically, we first give a detailed description of principles to help the readers quickly capture the key ideas of SSM. After that, we dive into the reviews of existing SSMs and their various applications, including natural language processing, computer vision, graph, multi-modal and multi-media, point cloud/event stream, time series data, and other domains. In addition, we give statistical comparisons and analysis of these models and hope it helps the readers to understand the effectiveness of different structures on various tasks. Then, we propose possible research points in this direction to better promote the development of the theoretical model and application of SSM. More related works will be continuously updated on the following GitHub: https://github.com/Event-AHU/Mamba\_State\_Space\_Model\_Paper\_List.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Multimedia},
  annotation = {TLDR: The first comprehensive review of existing SSMs and their various applications is given and possible research points are proposed to better promote the development of the theoretical model and application of SSM.},
  file = {C\:\\Users\\Sisyphus\\Zotero\\storage\\K62GY7FN\\Wang 等 - 2024 - State Space Model for New-Generation Network Alternative to Transformers A Survey.pdf;C\:\\Users\\Sisyphus\\Zotero\\storage\\NV8DP663\\2404.html}
}

@article{zhangOptimalControlView,
  title = {An Optimal Control View of {{LoRA}} and Binary Controller Design for Vision Transformers},
  author = {Zhang, Chi and Cheng, Jingpu and Li, Qianxiao},
  abstract = {While recent advancements in model fine-tuning predominantly emphasize the utilization of low-rank adaptation (LoRA), we propose an alternative approach centered on reducing the precision of adaptation matrices. In particular, we depart from the common viewpoint that considers adaptation matrices solely as weight differences, and reinterpret them as ``control variables'' to perturb pre-trained ViT systems. This new perspective enables the establishment of a control-oriented framework, facilitating the exploration of optimal controls guided by the Pontryagin Maximum Principle. Furthermore, we demonstrate that for bounded control sets such as hypercubes, the optimal controls often take on boundary values, leading naturally to a binary controller design. Theoretical analysis reveals that employing a binary control strategy achieves the same reachable state as its full-precision counterpart in the continuous idealisation of deep residual structures, a finding corroborated by later empirical investigations. Our studies further indicate that the controller's rank holds greater significance than its precision. As such, opting for low-precision yet high-rank controls is demonstrated to obtain better performance for practical vision tasks.},
  langid = {english},
  file = {C:\Users\Sisyphus\Zotero\storage\EJGXU4VR\Zhang 等 - An Optimal Control View of LoRA and Binary Controller Design for Vision Transformers.pdf}
}

@article{zhangParameterefficientFinetuningControls,
  title = {Parameter-Efficient Fine-Tuning with Controls},
  author = {Zhang, Chi and Cheng, Jingpu and Xu, Yanyu and Li, Qianxiao},
  abstract = {In contrast to the prevailing interpretation of LowRank Adaptation (LoRA) as a means of simulating weight changes in model adaptation, this paper introduces an alternative perspective by framing it as a control process. Specifically, we conceptualize lightweight matrices in LoRA as control modules tasked with perturbing the original, complex, yet frozen blocks on downstream tasks. Building upon this new understanding, we conduct a thorough analysis on the controllability of these modules, where we identify and establish sufficient conditions that facilitate their effective integration into downstream controls. Moreover, the control modules are redesigned by incorporating nonlinearities through a parameter-free attention mechanism. This modification allows for the intermingling of tokens within the controllers, enhancing the adaptability and performance of the system. Empirical findings substantiate that, without introducing any additional parameters, this approach surpasses the LoRA algorithms across all assessed datasets and rank configurations.},
  langid = {english},
  file = {C:\Users\Sisyphus\Zotero\storage\AERIBW2E\Zhang 等 - Parameter-Efficient Fine-Tuning with Controls.pdf}
}
